---
layout: post
title:  "Gradient de la politique"
date:   2021-04-09 21:07:00 +0200
categories: Apprentissage-profond
---

Traduit depuis [Lil'Log](https://lilianweng.github.io/lil-log/2018/02/19/a-long-peek-into-reinforcement-learning.html#policy-iteration).



<br/>

## Qu‚Äôest-ce que le Gradient de la Politique ?

Le Gradient de la Politique (ou *Policy Gradient*) est une approche de r√©solution de probl√®mes en Apprentissage par Renforcement.

En apprentissage par renforcement, l‚Äôobjectif est de trouver une strat√©gie de comportement optimale pour un agent, de sorte qu‚Äôil puisse obtenir les r√©compenses optimales. Les m√©thodes de **gradient de la politique** visent √† mod√©liser et √† optimiser la politique directement. La politique g√©n√©ralement mod√©lis√©e par une fonction param√©trique de <img src="https://latex.codecogs.com/svg.image?\theta" title="\theta" />, not√©e <img src="https://latex.codecogs.com/svg.image?\pi_\theta(a|s)" title="\pi_\theta(a|s)" />. Les valeurs de la fonction de r√©compenses (fonction objectif) d√©pendent de cette politique. Plusieurs algorithmes peuvent √™tre appliqu√©s pour optimiser <img src="https://latex.codecogs.com/svg.image?\theta" title="\theta" />, pour permettre √† l‚Äôagent d‚Äôobtenir la meilleure r√©compense possible.
<br/>


### Notations

(Ajouter tableau notations)


La fonction de r√©compense (ou fonction de performance) est d√©finie par :
<p align="center">
	<img src="https://latex.codecogs.com/svg.image?J(\theta)=\sum_{s\in&space;S}&space;\mu(s)v_\pi(s)&space;=&space;\sum_{s\in&space;S}&space;\mu(s)\sum_{a\in&space;A}\pi_\theta(a|s)q_\pi(s)" title="J(\theta)=\sum_{s\in S} \mu(s)v_\pi(s) = \sum_{s\in S} \mu(s)\sum_{a\in A}\pi_\theta(a|s)q_\pi(s)" />
</p>

Avec <img src="https://latex.codecogs.com/svg.image?\mu(s)" title="\mu(s)" />: la distribution stationnaire de la cha√Øne markovienne sous la politique <img src="https://latex.codecogs.com/svg.image?\pi_\theta" title="\pi_\theta" />.

On cherche donc √† trouver les valeurs de <img src="https://latex.codecogs.com/svg.image?\theta" title="\theta" /> qui maximise la r√©compense. Ce probl√®me peut √™tre r√©solu via la m√©thode d'ascension de gradient :
<p align="center">
	<img src="https://latex.codecogs.com/svg.image?\theta_{t&plus;1}=&space;\theta_t&space;&plus;&space;\alpha*&space;\widehat{\nabla&space;J(\theta_t)}" title="\theta_{t+1}= \theta_t + \alpha* \widehat{\nabla J(\theta_t)}" />
</p>

O√π <img src="https://latex.codecogs.com/svg.image?\widehat{\nabla&space;J(\theta_t)}" title="\widehat{\nabla J(\theta_t)}" /> est une estimation stochastique dont l'esp√©rence est le gradient de la performance mesur√©e par rapport √† <img src="https://latex.codecogs.com/svg.image?\theta_t" title="\theta_t" />.

En d√©rivant, on obtient :
<p align="center">
	<img src="https://latex.codecogs.com/svg.image?&space;\nabla&space;J(\theta)=\sum_{s\in&space;S}&space;\nabla&space;\mu(s)&space;v_\pi(s)&space;&plus;&space;\mu(s)&space;\nabla&space;v_\pi(s)" title=" \nabla J(\theta)=\sum_{s\in S} \nabla \mu(s) v_\pi(s) + \mu(s) \nabla v_\pi(s)" />
</p>


Comment estimer <img src="https://latex.codecogs.com/svg.image?\nabla&space;\mu(s)" title="\nabla \mu(s)" />, dans les cas o√π l'on ne connait pas les dynamiques qui r√©gissent l'environnement dans lequel l'agent √©volue ?

Il existe un moyen de contourner le probl√®me, en √©crivant le gradient de la performance sous une forme simplifi√©e. C'est ce que permet de le th√©or√®me du Gradient de la Politique.

<br/>

### Th√©or√®me du Gradient de la Politique


Le th√©or√®me du Gradient la Politique s'√©nonce de la fa√ßon suivante :

<p align="center">
	<img src="https://latex.codecogs.com/svg.image?\begin{align*}&space;\nabla&space;J(\theta)&space;&=&space;\nabla_\theta&space;\sum_{s\in&space;S}&space;\mu(s)&space;\sum_{a&space;\in&space;A}&space;q_\pi(s,a)&space;\pi_\theta(a|s)&space;\\&&space;\propto&space;\sum_{s\in&space;S}&space;\mu(s)&space;\sum_{a&space;\in&space;A}&space;q_\pi(s,a)&space;\nabla_\theta&space;\pi_\theta(a|s)\end{align*}" title="\begin{align*} \nabla J(\theta) &= \nabla_\theta \sum_{s\in S} \mu(s) \sum_{a \in A} q_\pi(s,a) \pi_\theta(a|s) \\& \propto \sum_{s\in S} \mu(s) \sum_{a \in A} q_\pi(s,a) \nabla_\theta \pi_\theta(a|s)\end{align*}" />
</p>

Cette formulation permet d'estimer le gradient de la performance en s'afranchissant du terme <img src="https://latex.codecogs.com/svg.image?\nabla&space;\mu(s)" title="\nabla \mu(s)" />.

#### Preuve


On distingue le **cas √©pisodique** du **cas continue**, pour lesquels la fonction de performance ne s'exprime pas exactement de la m√™me mani√®re.

<ins>Remarque :</ins> Pour simplifier l'√©criture, on notera implicitement : <img src="https://latex.codecogs.com/svg.image?\nabla&space;\doteq&space;\nabla_\theta" title="\nabla \doteq \nabla_\theta" />, et <img src="https://latex.codecogs.com/svg.image?\pi(a|s)\doteq\pi_\theta(a|s)" title="\pi(a|s)\doteq\pi_\theta(a|s)" />.

**Cas √©pisodique**
 
<p align="center">
	<img src="https://latex.codecogs.com/svg.image?\begin{align*}&space;\nabla&space;v_\pi(s)&space;&=&space;\nabla&space;\sum_{a&space;\in&space;A}&space;\pi(a|s)&space;q_\pi(s,a)&space;\\&=&space;\sum_{a&space;\in&space;A}&space;(\nabla&space;\pi(a|s)&space;q_\pi(s,a)&space;&plus;&space;\pi(a|s)&space;\nabla&space;q_\pi(s,a))&space;\\&=&space;\sum_{a&space;\in&space;A}&space;(\nabla&space;\pi(a|s)&space;q_\pi(s,a)&space;&plus;&space;\pi(a|s)&space;\nabla&space;(\sum_{r,s^\prime}p(r,s^\prime|s,a)(r&plus;v_\pi(s^\prime))))&space;\\&=&space;\sum_{a&space;\in&space;A}&space;(\nabla&space;\pi(a|s)&space;q_\pi(s,a)&space;&plus;&space;\pi(a|s)&space;\nabla&space;\sum_{s^\prime}p(s^\prime|s,a)(r&plus;v_\pi(s^\prime)))&space;\\\nabla&space;v_\pi(s)&space;&=&space;\sum_{a&space;\in&space;A}&space;(\nabla&space;\pi(a|s)&space;q_\pi(s,a)&space;&plus;&space;\pi(a|s)&space;\sum_{s^\prime}p(s^\prime|s,a)&space;\nabla&space;v_\pi(s^\prime))\end{align*}" title="\begin{align*} \nabla v_\pi(s) &= \nabla \sum_{a \in A} \pi(a|s) q_\pi(s,a) \\&= \sum_{a \in A} (\nabla \pi(a|s) q_\pi(s,a) + \pi(a|s) \nabla q_\pi(s,a)) \\&= \sum_{a \in A} (\nabla \pi(a|s) q_\pi(s,a) + \pi(a|s) \nabla (\sum_{r,s^\prime}p(r,s^\prime|s,a)(r+v_\pi(s^\prime)))) \\&= \sum_{a \in A} (\nabla \pi(a|s) q_\pi(s,a) + \pi(a|s) \nabla \sum_{s^\prime}p(s^\prime|s,a)(r+v_\pi(s^\prime))) \\\nabla v_\pi(s) &= \sum_{a \in A} (\nabla \pi(a|s) q_\pi(s,a) + \pi(a|s) \sum_{s^\prime}p(s^\prime|s,a) \nabla v_\pi(s^\prime))\end{align*}" />
</p>


On obtient une forme recursive, reliant l'√©tat s √† l'√©tat suivant s'.


Pour simplifier l'√©criture, posons : <img src="https://latex.codecogs.com/svg.image?\phi(s)&space;\doteq&space;\sum_{a&space;\in&space;A}&space;\nabla&space;\pi(a|s)q_\pi(s,a)" title="\phi(s) \doteq \sum_{a \in A} \nabla \pi(a|s)q_\pi(s,a)" />.

Soit <img src="https://latex.codecogs.com/svg.image?p_\pi(s\rightarrow&space;s^\prime,&space;k)" title="p_\pi(s\rightarrow s^\prime, k)" /> la probabilit√© de transitionner d'un √©tat s √† s' en suivant la politique <img src="https://latex.codecogs.com/svg.image?\pi_\theta" title="\pi_\theta" />. On notera <img src="https://latex.codecogs.com/svg.image?p_\pi(s\rightarrow&space;s^\prime,&space;k)&space;=&space;p(s\rightarrow&space;s^\prime,&space;k)" title="p_\pi(s\rightarrow s^\prime, k) = p(s\rightarrow s^\prime, k)" /> par commodit√© d'√©criture.

Cette probabilit√© s'exprime comme produit de la probabilit√© de choisir l'action a √† partir de s (li√©e √† la politique), et de la probabilit√© d'atteindre l'√©tat s' en partant de l'√©tat s et de l'action a (probabilit√© li√©e aux dynamiques de l'environnement). On somme les probabilit√©s sur chaque action pour obtenir la probabilit√© de transition : <img src="https://latex.codecogs.com/svg.image?p(s\rightarrow&space;s^\prime,&space;k=1)=\sum_a&space;\pi(a|s)p(s^\prime|s,a)" title="p(s\rightarrow s^\prime, k=1)=\sum_a \pi(a|s)p(s^\prime|s,a)" />.

Notons par ailleurs que l'on peut exprimer la probabilit√© de transitionner d'un √©tat vers un autre sur plusieurs pas sous la forme d'un produit des probabilit√©s des transitions interm√©diaires. Pour <img src="https://latex.codecogs.com/svg.image?\forall&space;(s,s^\prime,s^{\prime\prime})&space;\in&space;S^3" title="\forall (s,s^\prime,s^{\prime\prime}) \in S^3" />, et <img src="https://latex.codecogs.com/svg.image?\forall&space;k\in\mathbb{N}^{*}" title="\forall k\in\mathbb{N}^{*}" />, on a : <img src="https://latex.codecogs.com/svg.image?p_\pi(s\rightarrow&space;s^{\prime\prime},&space;k)&space;=&space;p(s\rightarrow&space;s^\prime,&space;k-1)&space;p(s^\prime&space;\rightarrow&space;s^{\prime\prime},&space;1)" title="p_\pi(s\rightarrow s^{\prime\prime}, k) = p(s\rightarrow s^\prime, k-1) p(s^\prime \rightarrow s^{\prime\prime}, 1)" />.

Gr√¢ce √† ces expression, on peut d√©rouler la r√©cursion :

<p align="center">
	<img src="https://latex.codecogs.com/svg.image?\begin{align*}&space;\nabla&space;v_\pi(s)&space;&=&space;\phi(s)&plus;&space;\sum_{a&space;\in&space;A}&space;\pi(a|s)&space;\sum_{s^\prime}p(s^\prime|s,a)&space;\nabla&space;v_\pi(s^\prime)&space;\\&=&space;\phi(s)&space;&plus;&space;p(s\rightarrow&space;s^\prime,1)&space;\nabla&space;v_\pi(s^\prime)&space;\\&=&space;\phi(s)&space;&plus;&space;p(s\rightarrow&space;s^\prime,1)(\phi(s^\prime)&space;&plus;&space;p(s^\prime&space;\rightarrow&space;s^{\prime&space;\prime},1)\nabla&space;v_\pi(s^{\prime&space;\prime}))&space;\\&=&space;\phi(s)&space;&plus;&space;p(s\rightarrow&space;s^\prime,1)\phi(s^\prime)&space;&plus;&space;p(s&space;\rightarrow&space;s^{\prime&space;\prime},2)\nabla&space;v_\pi(s^{\prime&space;\prime})&space;\\&=&space;\phi(s)&space;&plus;&space;p(s\rightarrow&space;s^\prime,1)\phi(s^\prime)&space;&plus;&space;p(s&space;\rightarrow&space;s^{\prime&space;\prime},2)\phi(s^{\prime&space;\prime})&space;&plus;&space;p(s&space;\rightarrow&space;s^{\prime&space;\prime&space;\prime},3)\phi(s^{\prime&space;\prime&space;\prime})&space;&plus;&space;...\\\nabla&space;v_\pi(s)&space;&=&space;\sum_{x&space;\in&space;S}&space;\sum_{k=0}^{\infty}p(s\rightarrow&space;x,&space;k)\phi(s)\end{align*}" title="\begin{align*} \nabla v_\pi(s) &= \phi(s)+ \sum_{a \in A} \pi(a|s) \sum_{s^\prime}p(s^\prime|s,a) \nabla v_\pi(s^\prime) \\&= \phi(s) + p(s\rightarrow s^\prime,1) \nabla v_\pi(s^\prime) \\&= \phi(s) + p(s\rightarrow s^\prime,1)(\phi(s^\prime) + p(s^\prime \rightarrow s^{\prime \prime},1)\nabla v_\pi(s^{\prime \prime})) \\&= \phi(s) + p(s\rightarrow s^\prime,1)\phi(s^\prime) + p(s \rightarrow s^{\prime \prime},2)\nabla v_\pi(s^{\prime \prime}) \\&= \phi(s) + p(s\rightarrow s^\prime,1)\phi(s^\prime) + p(s \rightarrow s^{\prime \prime},2)\phi(s^{\prime \prime}) + p(s \rightarrow s^{\prime \prime \prime},3)\phi(s^{\prime \prime \prime}) + ...\\\nabla v_\pi(s) &= \sum_{x \in S} \sum_{k=0}^{\infty}p(s\rightarrow x, k)\phi(s)\end{align*}" />
</p>


Le th√©or√®me du gradient de la politique fait intervenir la distribution stationnaire des √©tats <img src="https://latex.codecogs.com/svg.image?\mu_\pi(s)" title="\mu_\pi(s)" /> - not√©e <img src="https://latex.codecogs.com/svg.image?\mu(s)" title="\mu(s)" />) - d√©finit de la fa√ßon suivante :
<p align="center">
	<img src="https://latex.codecogs.com/svg.image?\mu(s)&space;\doteq&space;\frac{\eta(s)&space;}{\sum_{s^\prime&space;\in&space;S}\eta(s^\prime)}" title="\mu(s) \doteq \frac{\eta(s) }{\sum_{s^\prime \in S}\eta(s^\prime)}" />
</p>
O√π <img src="https://latex.codecogs.com/svg.image?\eta(s)" title="\eta(s)" /> est l'esp√©rence du nombre de visite de s sur un √©pisode, soit : <img src="https://latex.codecogs.com/svg.image?\eta(s)&space;\doteq&space;\sum_{k=0}^{\infty}p(s_0\to&space;s&space;|k)" title="\eta(s) \doteq \sum_{k=0}^{\infty}p(s_0\to s |k)" />.

Cette derni√®re forme peut nous permettre d'exprimer les probabilit√©s de transition sous forme d'esp√©rence du nombre de visite, pour faire appara√Ætre la distribution stationnaire. 

Rappelons enfin que la performance correspond √† la r√©compense esp√©r√©e sur l'√©pisode en suivant <img src="https://latex.codecogs.com/svg.image?\pi" title="\pi" /> √† partir de l'√©tat initial, soit : <img src="https://latex.codecogs.com/svg.image?J(\theta)&space;\doteq&space;v(s_0)" title="J(\theta) \doteq v(s_0)" />. 

Nous avons maintenant tous les √©l√©ments pour finir la d√©monstration :

<p align="center">
	<img src="https://latex.codecogs.com/svg.image?\begin{align*}&space;\nabla&space;J(\theta)&space;&=&space;\nabla&space;v(s_0)\\&=&space;\sum_{x&space;\in&space;S}&space;\sum_{k=0}^{\infty}p(s\rightarrow&space;x,&space;k)\sum_{a&space;\in&space;A}&space;\nabla&space;\pi(a|x)q_\pi(x,a)&space;\\&=&space;\sum_{x&space;\in&space;S}&space;\eta&space;(x)&space;\sum_{a&space;\in&space;A}&space;\nabla&space;\pi(a|x)&space;q_\pi(x,a)&space;\\&=&space;\sum_{x&space;\in&space;S}&space;(\sum_{s^\prime}&space;\eta(s^\prime))\frac{\eta&space;(x)}{\sum_{s^\prime}&space;\eta(s^\prime)}&space;\sum_{a&space;\in&space;A}&space;\nabla&space;\pi(a|x)&space;q_\pi(x,a)&space;\\\nabla&space;J(\theta)&space;&=&space;\sum_{s^\prime}&space;\eta(s^\prime)&space;\sum_{x&space;\in&space;S}&space;\mu(s)&space;\sum_{a&space;\in&space;A}&space;\nabla&space;\pi(a|x)&space;q_\pi(x,a)&space;\\\nabla&space;J(\theta)&space;&\propto&space;\sum_{x&space;\in&space;S}&space;\mu(s)&space;\sum_{a&space;\in&space;A}&space;\nabla&space;\pi(a|x)&space;q_\pi(x,a)\end{align*}" title="\begin{align*} \nabla J(\theta) &= \nabla v(s_0)\\&= \sum_{x \in S} \sum_{k=0}^{\infty}p(s\rightarrow x, k)\sum_{a \in A} \nabla \pi(a|x)q_\pi(x,a) \\&= \sum_{x \in S} \eta (x) \sum_{a \in A} \nabla \pi(a|x) q_\pi(x,a) \\&= \sum_{x \in S} (\sum_{s^\prime} \eta(s^\prime))\frac{\eta (x)}{\sum_{s^\prime} \eta(s^\prime)} \sum_{a \in A} \nabla \pi(a|x) q_\pi(x,a) \\\nabla J(\theta) &= \sum_{s^\prime} \eta(s^\prime) \sum_{x \in S} \mu(s) \sum_{a \in A} \nabla \pi(a|x) q_\pi(x,a) \\\nabla J(\theta) &\propto \sum_{x \in S} \mu(s) \sum_{a \in A} \nabla \pi(a|x) q_\pi(x,a)\end{align*}" />
</p>


 
**Cas continue**

Dans le cas continue, on d√©finit la performance sous la forme de r√©compense moyenne par pas de temps :
<p align="center">
	<img src="https://latex.codecogs.com/svg.image?\begin{align*}&space;J(\theta)&space;&\doteq&space;r(\pi)&space;\doteq&space;\displaystyle&space;\lim_{h&space;\to&space;\infty}&space;\sum_{t=1}^{h}\mathop{\mathbb{E}}[R_t|S_0,A_{0&space;:&space;t-1}\sim\pi]&space;\\&&space;=&space;\lim_{h&space;\to&space;\infty}&space;\mathop{\mathbb{E}}[R_t|S_0,A_{0&space;:&space;t-1}\sim\pi]&space;\\&&space;=&space;\sum_s&space;\mu(s)&space;\sum_a&space;\pi(a|s)&space;\sum_{s^\prime,r}&space;p(^\prime,r|s,a)r\end{align*}" title="\begin{align*} J(\theta) &\doteq r(\pi) \doteq \displaystyle \lim_{h \to \infty} \sum_{t=1}^{h}\mathop{\mathbb{E}}[R_t|S_0,A_{0 : t-1}\sim\pi] \\& = \lim_{h \to \infty} \mathop{\mathbb{E}}[R_t|S_0,A_{0 : t-1}\sim\pi] \\& = \sum_s \mu(s) \sum_a \pi(a|s) \sum_{s^\prime,r} p(^\prime,r|s,a)r\end{align*}" />
</p>


En outre, <img src="https://latex.codecogs.com/svg.image?v_{\pi}" title="v_{\pi}" /> et <img src="https://latex.codecogs.com/svg.image?q_{\pi}" title="q_{\pi}" /> sont fonctions du retour diff√©rentiel, d√©finit comme la diff√©rence entre la r√©compense obtenue √† chaque pas, et la r√©compense moyenne : 
<p align="center">
	<img src="https://latex.codecogs.com/svg.image?G_t&space;=&space;R_{t&plus;1}&space;-&space;r(\pi)&space;&plus;&space;R_{t&plus;2}&space;-&space;r(\pi)&space;&plus;&space;..." title="G_t = R_{t+1} - r(\pi) + R_{t+2} - r(\pi) + ..." />
</p>

On proc√®de d'une fa√ßon analogue au cas √©pisodique :
<p align="center">
	<img src="https://latex.codecogs.com/svg.image?\begin{align*}&space;\nabla&space;v_\pi(s)&space;&&space;=&space;\nabla&space;\sum_a&space;\pi(a|s)q_\pi(s,a)&space;\\&&space;=&space;\sum_a&space;(\nabla\pi(a|s)&space;q_\pi(s,a)&plus;\pi(a|s)&space;\nabla&space;q_\pi(a,s)&space;)&space;\\&&space;=&space;\sum_a&space;(\nabla\pi(a|s)&space;q_\pi(s,a)&plus;\pi(a|s)&space;\nabla\sum_{s^\prime,r}&space;p(s^\prime,r|s,a)(r-r(\theta)&plus;v_\pi(s)))\\&=&space;\sum_a&space;(\nabla\pi(a|s)&space;q_\pi(s,a)&plus;\pi(a|s)&space;\sum_{s^\prime,r}&space;p(s^\prime,r|s,a)(-\nabla&space;r(\theta)&plus;\nabla&space;v_\pi(s^\prime)))&space;\\&=&space;\sum_a&space;(\nabla\pi(a|s)&space;q_\pi(s,a)&plus;\pi(a|s)&space;\sum_{s^\prime}&space;p(s^\prime|s,a)(-\nabla&space;r(\theta)&plus;\nabla&space;v_\pi(s^\prime)))&space;\\&&space;=&space;\sum_a&space;(\nabla\pi(a|s)&space;q_\pi(s,a)&space;-&space;\pi(a|s)\nabla&space;r(\theta)&space;&plus;&space;\pi(a|s)&space;\sum_{s^\prime}&space;p(s^\prime|s,a)\nabla&space;v_\pi(s^\prime))&space;\end{align*}" title="\begin{align*} \nabla v_\pi(s) & = \nabla \sum_a \pi(a|s)q_\pi(s,a) \\& = \sum_a (\nabla\pi(a|s) q_\pi(s,a)+\pi(a|s) \nabla q_\pi(a,s) ) \\& = \sum_a (\nabla\pi(a|s) q_\pi(s,a)+\pi(a|s) \nabla\sum_{s^\prime,r} p(s^\prime,r|s,a)(r-r(\theta)+v_\pi(s)))\\&= \sum_a (\nabla\pi(a|s) q_\pi(s,a)+\pi(a|s) \sum_{s^\prime,r} p(s^\prime,r|s,a)(-\nabla r(\theta)+\nabla v_\pi(s^\prime))) \\&= \sum_a (\nabla\pi(a|s) q_\pi(s,a)+\pi(a|s) \sum_{s^\prime} p(s^\prime|s,a)(-\nabla r(\theta)+\nabla v_\pi(s^\prime))) \\& = \sum_a (\nabla\pi(a|s) q_\pi(s,a) - \pi(a|s)\nabla r(\theta) + \pi(a|s) \sum_{s^\prime} p(s^\prime|s,a)\nabla v_\pi(s^\prime)) \end{align*}" />
</p>

Ce qui nous permet d'isoler <img src="https://latex.codecogs.com/svg.image?\nabla&space;r(\theta)&space;" title="\nabla r(\theta) " /> :

<p align="center">
	<img src="https://latex.codecogs.com/svg.image?\nabla&space;r(\theta)&space;=&space;\sum_a&space;\nabla\pi(a|s)q_\pi(s,a)&space;&plus;&space;\sum_a&space;\pi(a|s)\sum_{s^\prime}p(s^\prime|s,a)\nabla&space;v_\pi(s^\prime)-\nabla&space;v_\pi(s)" title="\nabla r(\theta) = \sum_a \nabla\pi(a|s)q_\pi(s,a) + \sum_a \pi(a|s)\sum_{s^\prime}p(s^\prime|s,a)\nabla v_\pi(s^\prime)-\nabla v_\pi(s)" />
</p>

Par d√©finition, <img src="https://latex.codecogs.com/svg.image?J(\theta)=r(\theta)" title="J(\theta)=r(\theta)" />. Or <img src="https://latex.codecogs.com/svg.image?r(\theta)" title="r(\theta)" /> est ind√©pendant de s. L'√©quation du gradient de la performance est donc toujours juste si l'on multiplie le terme de droite par <img src="https://latex.codecogs.com/svg.image?\sum_s&space;\mu(s)" title="\sum_s \mu(s)" />, puisque <img src="https://latex.codecogs.com/svg.image?\sum_s&space;\mu(s)&space;=&space;1" title="\sum_s \mu(s) = 1" />.

Ainsi :
<p align="center">
	<img src="https://latex.codecogs.com/svg.image?\begin{align*}&space;\nabla&space;J(\theta)&space;&=&space;\sum_s&space;\mu(s)&space;(\sum_a&space;(\nabla\pi(a|s)q_\pi(s,a)&space;&plus;&space;\pi(a|s)\sum_{s^\prime}p(s^\prime|s,a)\nabla&space;v_\pi(s^\prime))-\nabla&space;v_\pi(s))&space;\\&=&space;\sum_s&space;\mu(s)&space;\sum_a&space;\nabla\pi(a|s)q_\pi(s,a)&space;&plus;&space;\sum_{s^\prime}&space;\sum_{s}&space;\mu(s)&space;\sum_a&space;\pi(a|s)p(s^\prime|s,a)\nabla&space;v_\pi(s^\prime)&space;-&space;\sum_s&space;\mu(s)&space;\nabla&space;v_\pi(s)&space;\\&=&space;\sum_s&space;\mu(s)&space;\sum_a&space;\nabla\pi(a|s)q_\pi(s,a)&space;&plus;&space;\sum_{s^\prime}&space;\mu(s^\prime)\nabla&space;v_\pi(s^\prime)&space;-&space;\sum_s&space;\mu(s)&space;\nabla&space;v_\pi(s)&space;\\\nabla&space;J(\theta)&space;&=&space;\sum_s&space;\mu(s)&space;\sum_a&space;\nabla\pi(a|s)q_\pi(s,a)\end{align*}" title="	" />
</p>

On retrouve la m√™me forme que dans le cas √©pisodique. 



**En r√©sum√©**

Dans les deux cas, on a donc :
<p align="center">
	<img src="https://latex.codecogs.com/svg.image?\nabla&space;J(\theta)&space;\propto&space;\sum_{s\in&space;S}&space;\mu(s)&space;\sum_{a&space;\in&space;A}&space;q_\pi(s,a)&space;\nabla_\theta&space;\pi_\theta(a|s)" title="\nabla J(\theta) \propto \sum_{s\in S} \mu(s) \sum_{a \in A} q_\pi(s,a) \nabla_\theta \pi_\theta(a|s)" />
</p>

Avec pour coefficient de proportionnalit√©:
- <img src="https://latex.codecogs.com/svg.image?\sum_{s}&space;\eta(s)" title="\sum_{s} \eta(s)" /> dans le cas √©pisodique ;
- 1 dans le cas continue.



<br/>

### G√©n√©ralisation aux algorithmes du gradient de la politique

Le th√©or√®me du gradient de la politique nous permet d'exprimer le gradient de la performance d'une mani√®re simple et √©l√©gante :

<p align="center">
	<img src="https://latex.codecogs.com/svg.image?\begin{align*}&space;\nabla&space;J(\theta)&space;&\propto&space;\sum_{s&space;\in&space;S}&space;\mu(s)&space;\sum_{a&space;\in&space;A}&space;q_\pi(s,a)&space;\nabla&space;\pi(a|s)&space;\\&&space;=&space;\sum_{s&space;\in&space;S}&space;\mu(s)&space;\sum_{a&space;\in&space;A}&space;\pi(a|s)&space;q_\pi(s,a)&space;\frac{\nabla&space;\pi(a|s)}{\pi(a|s)}&space;&space;\\\nabla&space;J&space;(\theta)&space;&=&space;\mathop{\mathbb{E}}_{s\sim&space;\mu_\pi,&space;a\sim&space;\pi_0}&space;[q_\pi(s,a)&space;\nabla&space;\ln\pi(a|s)]\\\end{align*}" title="\begin{align*} \nabla J(\theta) &\propto \sum_{s \in S} \mu(s) \sum_{a \in A} q_\pi(s,a) \nabla \pi(a|s) \\& = \sum_{s \in S} \mu(s) \sum_{a \in A} \pi(a|s) q_\pi(s,a) \frac{\nabla \pi(a|s)}{\pi(a|s)} \\\nabla J (\theta) &= \mathop{\mathbb{E}}_{s\sim \mu_\pi, a\sim \pi_0} [q_\pi(s,a) \nabla \ln\pi(a|s)]\\\end{align*}" />
</p>

Cette forme constitue les fondements de la plupart des algorithmes du gradient de la politique. Elle a pour particularit√© de ne **pas** avoir **de biais**, mais d'√™tre soumis √† une **forte variance**. Les algorithmes √©voqu√©s dans cet articles essayent de r√©duire la variance sans affecter le bias.

L'article Estimation de l'Avantage G√©n√©ralis√©e (GAE) [Schulman et al., 2016](https://arxiv.org/pdf/1506.02438.pdf) ((i) trad ?) propose une forme une forme g√©n√©rale du gradient de la performance, mettant en lumi√®re les diff√©rentes d√©clinaison de cette forme que l'on peut trouver dans la litt√©rature :

En posant g, le gradient de la performance, tel que <img src="https://latex.codecogs.com/svg.image?g&space;\doteq&space;\nabla_\theta&space;\mathop{\mathbb{E}}[\sum_{t=0}^\infty&space;r_t]" title="g \doteq \nabla_\theta \mathop{\mathbb{E}}[\sum_{t=0}^\infty r_t]" />

On a la forme g√©n√©rale : 
<p align="center">
	<img src="https://latex.codecogs.com/svg.image?g&space;=&space;\mathop{\mathbb{E}}[\sum_{t=0}^\infty&space;\Psi_t&space;\nabla_\theta&space;log&space;\pi_\theta(a_t|s_t)]" title="g = \mathop{\mathbb{E}}[\sum_{t=0}^\infty \Psi_t \nabla_\theta log \pi_\theta(a_t|s_t)]" />
</p>

Avec <img src="https://latex.codecogs.com/svg.image?\Psi_t" title="\Psi_t" />, l'une des fonctions suivantes :
- <img src="https://latex.codecogs.com/svg.image?\sum_{t=0}^\infty&space;r_{t}" title="\sum_{t=0}^\infty r_{t}" /> : retour total de la trajectoire
- <img src="https://latex.codecogs.com/svg.image?\sum_{t^\prime=t}^\infty&space;r_{t^\prime}" title="\sum_{t^\prime=t}^\infty r_{t^\prime}" /> : retour suivant l'action <img src="https://latex.codecogs.com/svg.image?a_t" title="a_t" />
- <img src="https://latex.codecogs.com/svg.image?\sum_{t^\prime=t}^\infty&space;r_{t^\prime}-b(s_t)" title="\sum_{t^\prime=t}^\infty r_{t^\prime}-b(s_t)" /> : formule pr√©c√©dente, avec valeurs de r√©f√©rences
- <img src="https://latex.codecogs.com/svg.image?q_\pi(s_t,a_t)" title="q_\pi(s_t,a_t)" /> : fonction de valeur d'√©tat-action
- <img src="https://latex.codecogs.com/svg.image?A_\pi(s_t,a_t)" title="A_\pi(s_t,a_t)" /> : fonction d'avantage
- <img src="https://latex.codecogs.com/svg.image?r_t&space;&plus;&space;v_\pi(s_{t&plus;1})-v_\pi(s_t)" title="r_t + v_\pi(s_{t+1})-v_\pi(s_t)" /> : r√©sidu TD (diff√©rence temporelle)


Avec les fonctions de valeurs : 
<p align="center">
	<img src="https://latex.codecogs.com/svg.image?v_\pi&space;(s_t)&space;\doteq&space;\mathop{\mathbb{E}}_{s_{t&plus;1}:\infty,a_t:\infty}[\sum_{l=0}^\infty&space;r_{t&plus;l}]" title="v_\pi (s_t) \doteq \mathop{\mathbb{E}}_{s_{t+1}:\infty,a_t:\infty}[\sum_{l=0}^\infty r_{t+l}]" />
	<img src="https://latex.codecogs.com/svg.image?q_\pi&space;(s_t,a_t)&space;\doteq&space;\mathop{\mathbb{E}}_{s_{t&plus;1}:\infty,a_{t&plus;1}:\infty}[\sum_{l=0}^\infty&space;r_{t&plus;l}]" title="q_\pi (s_t,a_t) \doteq \mathop{\mathbb{E}}_{s_{t+1}:\infty,a_{t+1}:\infty}[\sum_{l=0}^\infty r_{t+l}]" />
</p>

Et la fonction d'avantage : 
<p align="center">
	<img src="https://latex.codecogs.com/svg.image?A_\pi(s_t,a_t)&space;\doteq&space;q_\pi(s_t,a_t)-v_\pi(s_t)" title="A_\pi(s_t,a_t) \doteq q_\pi(s_t,a_t)-v_\pi(s_t)" />
</p>

<br/>

## Algorithmes du Gradient de la Politique

Dans tous les algorithmes suivant font mention du param√®tre <img src="https://latex.codecogs.com/svg.image?\gamma&space;\in&space;&space;\]0;1\]" title="\gamma \in \]0;1\]" />, le facteur de r√©duction. Sa d√©finition est implicite, afin d'√©viter les redondances.

<br/>

### REINFORCE

L'algorithme **REINFORCE** (gradient de la Politique avec m√©thode Monte-Carlo) repose sur l'expression du gradient de la performance obtenue dans le Th√©or√®me du Gradient de la Politique, appliqu√© aux √©chantillons d'√©pisodes. En constatant que <img src="https://latex.codecogs.com/svg.image?q_\pi(s_t,a_t)=&space;\mathop{\mathbb{E}}_\pi[G_t&space;|s_t,&space;a_t]" title="q_\pi(s_t,a_t)= \mathop{\mathbb{E}}_\pi[G_t |s_t, a_t]" />, on trouve :


<p align="center">
	<img src="https://latex.codecogs.com/svg.image?\begin{align*}&space;\nabla_\theta&space;J(\theta)&space;&=&space;\mathop{\mathbb{E}}_\pi[q_\pi(s,a)&space;\nabla_\theta\ln\pi_\theta(a,s)]&space;\\&=&space;\mathop{\mathbb{E}}_\pi[G_t&space;\nabla_\theta\ln\pi_\theta(a,s)]\end{align*}" title="\begin{align*} \nabla_\theta J(\theta) &= \mathop{\mathbb{E}}_\pi[q_\pi(s,a) \nabla_\theta\ln\pi_\theta(a,s)] \\&= \mathop{\mathbb{E}}_\pi[G_t \nabla_\theta\ln\pi_\theta(a,s)]\end{align*}" />
</p>

Autrement dit, on peut optimiser <img src="https://latex.codecogs.com/svg.image?\theta" title="\theta" /> √† partir du retour obtenu au cours d'un √©pisode. Cette approche exploite la trajectoire observ√©e sur l'√©pisode entier pour faire ses mises √† jours, c'est pourquoi on parle de m√©thode de type Monte Carlo.

**Algorithme : REINFORCE (√©pisodique)**

<ins>Initialisation :</ins>
- D√©finir <img src="https://latex.codecogs.com/svg.image?\alpha" title="\alpha" />, le pas d'apprentissage associ√© √† la politique
- Initialiser al√©atoirement <img src="https://latex.codecogs.com/svg.image?\theta&space;\in&space;\mathbb{R}^{d}" title="\theta \in \mathbb{R}^{d}" />, les poids associ√©s aux caract√©ristiques d√©finissant la politique

<ins>Ex√©cution :</ins>
- Pour chaque √©pisode :
	- G√©n√©rer la trajectoire <img src="https://latex.codecogs.com/svg.image?S_1,A_1,R_2,S_2,A_2,&space;...&space;,&space;A_{T-1},&space;S_T" title="S_1,A_1,R_2,S_2,A_2, ... , A_{T-1}, S_T" /> en suivant <img src="https://latex.codecogs.com/svg.image?\pi_\theta" title="\pi_\theta" />
	- Pour chaque √©tape de l'√©pisode <img src="https://latex.codecogs.com/svg.image?t=0,1,...,T-1,T" title="t=0,1,...,T-1,T" /> :
		- <img src="https://latex.codecogs.com/svg.image?G\leftarrow&space;\sum_{k=t&plus;1}^T&space;\gamma^{k-t-1}R_k" title="G\leftarrow \sum_{k=t+1}^T \gamma^{k-t-1}R_k" />
		- <img src="https://latex.codecogs.com/svg.image?\theta&space;\leftarrow&space;\theta&space;&plus;&space;\alpha&space;\gamma^t&space;\nabla\ln\pi(A_t|S_t,\theta)" title="\theta \leftarrow \theta + \alpha \gamma^t \nabla\ln\pi(A_t|S_t,\theta)" />

<br/>

### REINFORCE avec valeurs de r√©f√©rence

L'algorithme **REINFORCE avec valeurs de r√©f√©rence** est variante bien connue de l'algorithme REINFORCE. Il s'agit simplement de retrancher au retour de l'√©pisode un valeur de r√©f√©rence pour l'estimation du gradient de la performance. Cette modification a pour effet de **r√©duire la variance** tout en assurant l'absence de biais.

On utilise souvent la **valeur d'√©tat** en guise de valeur de r√©f√©rence, de sorte que l'on utilise la **fonction d'avantage** dans la mise √† jour du gradient.


(voir l'article en ref, et synth√©tiser. D√©mo en 3 lignes ? Intuition ?)


**Algorithme : REINFORCE avec valeurs de r√©f√©rence (√©pisodique)**

<ins>Initialisation :</ins>
- D√©finir :
	- <img src="https://latex.codecogs.com/svg.image?\alpha^w&space;\in&space;\mathbb{R}^{&plus;*}" title="\alpha^w \in \mathbb{R}^{+*}" />, le pas d'apprentissage associ√© aux valeurs d'√©tats
	- <img src="https://latex.codecogs.com/svg.image?\alpha^\theta&space;\in&space;\mathbb{R}^{&plus;*}" title="\alpha^\theta \in \mathbb{R}^{+*}" />, le pas d'apprentissage associ√© √† la politique
- Initialiser al√©atoirement :
	- <img src="https://latex.codecogs.com/svg.image?w&space;\in&space;\mathbb{R}^{d^\prime}" title="w \in \mathbb{R}^{d^\prime}" />, les poids associ√©s aux valeurs d'√©tats
	- <img src="https://latex.codecogs.com/svg.image?\theta&space;\in&space;\mathbb{R}^{d}" title="\theta \in \mathbb{R}^{d}" />, les poids associ√©s aux caract√©ristiques d√©finissant la politique
	
<ins>Ex√©cution :</ins>
- Pour chaque √©pisode :
	- G√©n√©rer la trajectoire <img src="https://latex.codecogs.com/svg.image?S_1,A_1,R_2,S_2,A_2,&space;...&space;,&space;A_{T-1},&space;S_T" title="S_1,A_1,R_2,S_2,A_2, ... , A_{T-1}, S_T" /> en suivant <img src="https://latex.codecogs.com/svg.image?\pi_\theta" title="\pi_\theta" />
	- Pour chaque √©tape de l'√©pisode <img src="https://latex.codecogs.com/svg.image?t=0,1,...,T-1,T" title="t=0,1,...,T-1,T" /> :
		- <img src="https://latex.codecogs.com/svg.image?G\leftarrow&space;\sum_{k=t&plus;1}^T&space;\gamma^{k-t-1}R_k" title="G\leftarrow \sum_{k=t+1}^T \gamma^{k-t-1}R_k" />
		- <img src="https://latex.codecogs.com/svg.image?\delta&space;\leftarrow&space;G&space;-&space;\hat{v}(S_t,w)" title="\delta \leftarrow G - \hat{v}(S_t,w)" />
		- <img src="https://latex.codecogs.com/svg.image?w&space;\leftarrow&space;w&space;&plus;&space;\alpha^w&space;\delta&space;\nabla&space;\hat{v}(S_t,w)" title="w \leftarrow w + \alpha^w \delta \nabla \hat{v}(S_t,w)" />
		- <img src="https://latex.codecogs.com/svg.image?\theta&space;\leftarrow&space;\theta&space;&plus;&space;\alpha^\theta&space;\gamma^t&space;\delta&space;\nabla\ln\pi(A_t|S_t,\theta)" title="\theta \leftarrow \theta + \alpha^\theta \gamma^t \delta \nabla\ln\pi(A_t|S_t,\theta)" />





<br/>

### Acteur-Critique

L'algorithme **Acteur-Critique** ressemble beaucoup √† l'algorithme REINFORCE avec valeurs de r√©f√©rence : il s'agit de calculer une diff√©rence entre un retour, et une valeur de r√©f√©rence.


En revenche, deux diff√©rences importantes les distinguent :
- Comme toutes les m√©thodes de type Monte-Carlo, REINFORCE ne fait pas de mise-√†-jour avant la fin de l'√©pisode. Par ailleurs, la valeur de r√©f√©rence ne tient compte que de la valeur de l'√©tat initial (avant de prendre l'action), et ne permet par cons√©quent pas de juger de la qualit√© de l'action choisie. Par cette approche, on r√©pond √† la question : **"L'agent a-t-il bien fait de se trouver √† cette position au temps t ?"**, en tenant compte de l'√©pisode entier.
- Dans la m√©thode Acteur critique, le retour utilis√© dans la mise √† jour des param√®tres de la poltique exploite la valeur de l'√©tat au temps t, et de la valeur de l'√©tat suivant ; c'est le retour 1-pas, not√© <img src="https://latex.codecogs.com/svg.image?G_{t:t&plus;1}" title="G_{t:t+1}" /> (comme dans les m√©thodes TD(0), SARSA(0) ou Q-apprentissage). Cette approche permet donc d'√©valuer la diff√©rence de valeur entre l'√©tat initial et le nouvel √©tat, autrement dit de juger de la qualit√© de l'action prise par l'agent. on r√©pond ici √† la question : **"L'agent a-t-il bien fait de choisir cette action au temps t?"**, en ne tenant compte que de la transition entre les temps t et t+1.

En r√©sum√© : la politique agit, et le retour 1-pas critique.


**Algorithme : Acteur-critique (√©pisodique)**

<ins>Initialisation :</ins>
- D√©finir :
	- <img src="https://latex.codecogs.com/svg.image?\alpha^w&space;\in&space;\mathbb{R}^{&plus;*}" title="\alpha^w \in \mathbb{R}^{+*}" />, le pas d'apprentissage associ√© aux valeurs d'√©tats
	- <img src="https://latex.codecogs.com/svg.image?\alpha^\theta&space;\in&space;\mathbb{R}^{&plus;*}" title="\alpha^\theta \in \mathbb{R}^{+*}" />, le pas d'apprentissage associ√© √† la politique
- Initialiser al√©atoirement :
	- <img src="https://latex.codecogs.com/svg.image?w&space;\in&space;\mathbb{R}^{d^\prime}" title="w \in \mathbb{R}^{d^\prime}" />, les poids associ√©s aux valeurs d'√©tats
	- <img src="https://latex.codecogs.com/svg.image?\theta&space;\in&space;\mathbb{R}^{d}" title="\theta \in \mathbb{R}^{d}" />, les poids associ√©s aux caract√©ristiques d√©finissant la politique
	
<ins>Ex√©cution :</ins>
- Pour chaque √©pisode :
	- Initialiser S (premier √©tat de l'√©pisode)
	- <img src="https://latex.codecogs.com/svg.image?I&space;\leftarrow&space;1" title="I \leftarrow 1" /> (coefficient de r√©duction cumul√©e)
	- Tant que S n'est pas terminal (pour chaque pas de temps) :
		- <img src="https://latex.codecogs.com/svg.image?A&space;\sim&space;\pi(\cdot|s,\theta)" title="A \sim \pi(\cdot|s,\theta)" />
		- Appliquer l'action A, observer (S',R)
		- <img src="https://latex.codecogs.com/svg.image?\delta&space;\leftarrow&space;R&space;&plus;&space;\gamma&space;\hat{v}(S^\prime,w)&space;-&space;\hat{v}(S,w)" title="\delta \leftarrow R + \gamma \hat{v}(S^\prime,w) - \hat{v}(S,w)" />
		- <img src="https://latex.codecogs.com/svg.image?w&space;\leftarrow&space;w&space;&plus;&space;\alpha^w&space;\delta&space;\nabla&space;\hat{v}(S,w)" title="w \leftarrow w + \alpha^w \delta \nabla \hat{v}(S,w)" />
		- <img src="https://latex.codecogs.com/svg.image?\theta&space;\leftarrow&space;\theta&space;&plus;&space;\alpha^\theta&space;I&space;\delta&space;\nabla\ln\pi(A|S,\theta)" title="\theta \leftarrow \theta + \alpha^\theta I \delta \nabla\ln\pi(A|S,\theta)" />
		- <img src="https://latex.codecogs.com/svg.image?I&space;\leftarrow&space;\gamma&space;I" title="I \leftarrow \gamma I" />
		- <img src="https://latex.codecogs.com/svg.image?S&space;\leftarrow&space;S^\prime" title="S \leftarrow S^\prime" />


Par convention, on a <img src="https://latex.codecogs.com/svg.image?\hat{v}(S^\prime,w)&space;\doteq&space;0" title="\hat{v}(S^\prime,w) \doteq 0" /> si S' est terminal. 



<br/>


### Acteur-Critique Hors-Politique


Tout les algorithmes jusqu'ici pr√©sent√©s optimisent la politique qui a √©t√© utilis√©e pour recolter les √©chantillons de trajectoires. Dans cette section, nous abordons une variante de l'algorithme Acteur-Critique dans laquelle **la politique d'exploration n'est pas la m√™me que la politique cible**. Une telle approche permet, entre autre, d'avoir la politique la plus efficace possible pour l'exploration, plut√¥t que de contraindre la politique que l'on est en train d'optimiser √† aller parfois explorer de nouvelles trajectoires.


(Ajouter d√©mo de la r√®gle de mise √† jour)



**Algorithme : Acteur-critique Hors-Politique (√©pisodique)**

<ins>Initialisation :</ins>
- D√©finir :
	- <img src="https://latex.codecogs.com/svg.image?e_v&space;\leftarrow&space;0" title="e_v \leftarrow 0" />, (trace d'√©ligibilit√© sur les valeurs ?)
	- <img src="https://latex.codecogs.com/svg.image?e_u&space;\leftarrow&space;0" title="e_u \leftarrow 0" />, (trace d'√©ligibilit√© sur la politique ?)
	- <img src="https://latex.codecogs.com/svg.image?w&space;\leftarrow&space;0" title="w \leftarrow 0" />, (? utilisation de w (i) ?)
	- <img src="https://latex.codecogs.com/svg.image?S&space;\leftarrow&space;S_0" title="S \leftarrow S_0" />, √©tat initial
- Initialiser al√©atoirement :
	- v, les poids associ√©s aux valeurs d'√©tats
	- u, les poids associ√©s aux caract√©ristiques d√©finissant la politique
	
<ins>Ex√©cution :</ins>
- Pour chaque √©tape :
	- <img src="https://latex.codecogs.com/svg.image?a&space;\sim&space;b(\cdot|s)" title="a \sim b(\cdot|s)" />
	- Appliquer l'action a, observer (s',r)
	- <img src="https://latex.codecogs.com/svg.image?\delta&space;\leftarrow&space;r&space;&plus;&space;\gamma(s^\prime)&space;v^Tx_{s^\prime}&space;-&space;v^Tx_s" title="\delta \leftarrow r + \gamma(s^\prime) v^Tx_{s^\prime} - v^Tx_s" />
	- <img src="https://latex.codecogs.com/svg.image?\rho&space;\leftarrow&space;\frac{\pi_u(a|s)}{b(a|s)}" title="\rho \leftarrow \frac{\pi_u(a|s)}{b(a|s)}" />
	- Mettre √† jour le critique :
		- <img src="https://latex.codecogs.com/svg.image?e_v&space;\leftarrow&space;\rho(x_s&plus;\gamma(s)\lambda&space;e_v)" title="e_v \leftarrow \rho(x_s+\gamma(s)\lambda e_v)" />
		- <img src="https://latex.codecogs.com/svg.image?v&space;\leftarrow&space;v&space;&plus;&space;\alpha_v[\delta&space;e_v&space;-&space;\gamma(s^\prime)(1-\lambda)(w^Te_v)x_s]" title="v \leftarrow v + \alpha_v[\delta e_v - \gamma(s^\prime)(1-\lambda)(w^Te_v)x_s]" />
		- <img src="https://latex.codecogs.com/svg.image?w&space;\leftarrow&space;w&space;&plus;&space;\alpha_w[\delta&space;e_v&space;-&space;(w^Tx_s)x_s]" title="w \leftarrow w + \alpha_w[\delta e_v - (w^Tx_s)x_s]" />
	- Mettre √† jour l'acteur :
		- <img src="https://latex.codecogs.com/svg.image?e_u&space;\leftarrow&space;\rho&space;[\frac{\nabla_u\pi_u(a|s)}{\pi_u(a|s)}&plus;\gamma(s)\lambda&space;e_u]" title="e_u \leftarrow \rho [\frac{\nabla_u\pi_u(a|s)}{\pi_u(a|s)}+\gamma(s)\lambda e_u]" />
		- <img src="https://latex.codecogs.com/svg.image?u&space;\leftarrow&space;u&space;&plus;&space;\alpha_u&space;\delta&space;e_u" title="u \leftarrow u + \alpha_u \delta e_u" />
	
	- <img src="https://latex.codecogs.com/svg.image?s&space;\leftarrow&space;s^\prime" title="s \leftarrow s^\prime" />
	

Avec <img src="https://latex.codecogs.com/svg.image?x_s" title="x_s" />, le vecteur de caract√©ristique correspondant √† l'√©tat observ√© <img src="https://latex.codecogs.com/svg.image?s" title="s" />.




---

La **Normalisation par lots** (en anglais ***Batch-Normalization*** - not√©e ***BN***) est une m√©thode algorithmique qui permet d‚Äôentra√Æner un r√©seau de neurones profond de mani√®re plus rapide et plus stable. 

Cette m√©thode consiste √† normaliser les vecteurs d‚Äôactivation des couches cach√©es en utilisant les caract√©ristiques statistiques du lot (ou *batch*) - la moyenne et l‚Äô√©cart-type - juste avant (ou juste apr√®s) le passage dans la fonction non-lin√©aire.


<img src="https://render.githubusercontent.com/render/math?math=\sum_s e^{i \pi} = -1">
<p align="center">
  <img src="https://raw.githubusercontent.com/Johann-Huber/Johann-Huber.github.io/master/assets/sbn_1a_fr.jpg">
  Sch√©ma 1.a Perceptron multicouche <strong>sans normalisation par lots (BN)</strong>
</p>

	
<p align="center">
  <img src="https://raw.githubusercontent.com/Johann-Huber/Johann-Huber.github.io/master/assets/sbn_1b_fr.jpg">
  Sch√©ma 1.b Perceptron multicouche <strong>avec normalisation par lots (BN)</strong>
</p>


Toutes les infrastructures de d√©veloppements (ou frameworks) populaires proposent des impl√©mentations de cette m√©thode sous la forme de couche computationnelle, que l‚Äôon peut facilement ins√©rer dans un r√©seau de neurones.




<ins>Article de r√©f√©rence :</ins> [‚ÄúBatch-normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift‚Äù](url=https://arxiv.org/abs/1502.03167) [1] (trad. ‚ÄúNormalisation par Lots : Acc√©l√©ration de l‚Äôentra√Ænement des r√©seaux de neurones profonds par la r√©duction du d√©calage de covariable interne‚Äù).

<ins>Article (contribution significative dans la compr√©hension du concept) :</ins> [‚ÄúHow does batch normalization help optimization‚Äù](url=https://arxiv.org/pdf/1805.11604.pdf) [2] (trad. ‚ÄúComment la normalisation par lots facilite l‚Äôoptimisation.‚Äù).


<br/>

## B) En 3 minutes

### 1. Principe

La normalisation par lot s‚Äôarticule diff√©remment pendant la phase d‚Äôentra√Ænement et la phase d‚Äô√©valuation.

#### 1.1. Phase d‚Äôentra√Ænement

Pour chaque couche cach√©e, on calcule la normalisation par lot de la fa√ßon suivante :

<p align="center">
  <img src="https://latex.codecogs.com/svg.image?(1)\hspace{0.2cm}\mu&space;=&space;\frac{1}{n}*\sum_{i}Z^{(i)}\hspace{2cm}(2)\hspace{0.2cm}\sigma&space;=&space;\frac{1}{n}*\sum_{i}(Z^{(i)}-\mu)" title="(1)\hspace{0.2cm}\mu = \frac{1}{n}*\sum_{i}Z^{(i)}\hspace{2cm}(2)\hspace{0.2cm}\sigma = \frac{1}{n}*\sum_{i}(Z^{(i)}-\mu)" /><img src="https://latex.codecogs.com/svg.image?(3)\hspace{0.2cm}Z_{(i)}^{norm}=\frac{Z^{(i)}-\mu}{\sqrt{\sigma&space;^2&space;&plus;&space;\epsilon}}\hspace{2cm}(4)\hspace{0.2cm}\breve{Z}=\gamma&space;*&space;Z^{(i)}_{norm}&plus;\beta" title="(3)\hspace{0.2cm}Z_{(i)}^{norm}=\frac{Z^{(i)}-\mu}{\sqrt{\sigma ^2 + \epsilon}}\hspace{2cm}(4)\hspace{0.2cm}\breve{Z}=\gamma * Z^{(i)}_{norm}+\beta" />	
</p>


- On calcule d‚Äôabord la moyenne ùúá et l‚Äô√©cart-type œÉ des vecteurs d‚Äôactivations √† l‚Äô√©chelle du lot ((1) et (2)).
- En utilisant ces valeurs, on normalise le vecteur d‚Äôactivation Z(i) (3). De cette fa√ßon, la distribution des valeurs d‚Äôactivations associ√©es √† chaque exemple du lot suit une loi normale centr√©e r√©duite. (ùúÄ est ici une constante de stabilisation num√©rique)


<p align="center">
  <img src="https://raw.githubusercontent.com/Johann-Huber/Johann-Huber.github.io/master/assets/sbn_2.jpg">
  <br/><strong>Sch√©ma 2 : 1√®re √©tape de la normalisation par lots.</strong> Exemple d‚Äôune couche de 3 neurones, avec un lot de taille b. Pour chaque neurone, les valeurs √† l‚Äô√©chelles du batch suivent une loi normal centr√©e r√©duite.
</p>


Finalement, on calcule les valeurs de **sortie de la couche de normalisation par lot** ·∫ê(i) en appliquant une transformation lin√©aire avec deux param√®tres √† entra√Æner (4). Cette derni√®re op√©ration permet au mod√®le de d√©finir √† chaque couche cach√©e la distribution optimale, en ajustant ces deux param√®tres :
- ùõæ permet de jouer sur l‚Äô√©talement de la gaussienne ;
- ùõΩ joue le r√¥le de biais, d√©calant √† gauche ou √† droite la gaussienne.


<p align="center">
  <img src="https://raw.githubusercontent.com/Johann-Huber/Johann-Huber.github.io/master/assets/sbn_3.jpg">
  <strong>Sch√©ma 3: Int√©r√™t des param√®tres ùõæ et ùõΩ.</strong> Les modifications sur la distribution (en haut) permettent d‚Äôexploiter diff√©rentes parties de la fonction non-lin√©aire (en bas).
</p>

<ins>Remarque :</ins> Les raisons qui rendent la couche BN efficace ont souvent fait l‚Äôobjet d‚Äôincompr√©hensions et d‚Äôerreurs, jusque dans l‚Äôarticle officiel. Des recherches r√©centes ont √©cart√©es certaines hypoth√®ses erron√©es, et ont permis une meilleure compr√©hension de cette technique. Ces aspects sont abord√©s plus largement dans la partie C.3 : ‚ÄúPourquoi la couche BN est-elle efficace ?‚Äù de cet article.


√Ä chaque it√©ration, le r√©seau calcule la moyenne ùúá et l‚Äô√©cart-type œÉ correspondant au lot en cours. Les param√®tres ùõæ et ùõΩ sont ajust√©s via la r√©tropropagation du gradient, en appliquant une [moyenne mobile](https://fr.wikipedia.org/wiki/Moyenne_mobile). De cette fa√ßon, l‚Äôajustement des param√®tres ùõæ et ùõΩ tiennent davantage compte des derni√®res it√©rations que des premi√®res. 

#### 1.2. Phase d‚Äô√©valuation

Contrairement √† la phase d‚Äôentra√Ænement, **on ne dispose pas forc√©ment d‚Äôun lot complet √† inf√©rer lors de l‚Äô√©valuation.**

Pour s‚Äôaffranchir de ce probl√®me, on d√©termine (ùúápop , œÉpop), tel que :
- ùúápop : estimation de la moyenne de la population √©tudi√©e ;
- œÉpop : estimation de l‚Äô√©cart-type de la population √©tudi√©e.

Ces valeurs sont d√©termin√©es √† partir des (ùúálot , œÉlot) rencontr√©s pendant l'entra√Ænement, et appliqu√©e syst√©matiquement dans l‚Äô√©quation (3), au lieu d‚Äôavoir recours aux √©quations (1) et (2).

<ins>Remarque :</ins> Cet aspect est plus largement d√©crit dans la partie C.2.3 : Param√®tres statistiques lors de la phase d‚Äô√©valuation‚Äù.

<br/>
### 2. En pratique

En pratique, on consid√®re la normalisation par lots comme une couche √† part enti√®re, au m√™me titre qu‚Äôun perceptron, qu‚Äôune couche de convolution, qu‚Äôune fonction d‚Äôactivation ou qu‚Äôun dropout.

On trouve la couche de normalisation par lots (ou couche BN) dans les infrastructures de d√©veloppements (ou *frameworks*) populaires.

| Librairie          | Couches BN
|--------------------|------------------------------------------------------------------|
| Pytorch            | torch.nn.BatchNorm1d, torch.nn.BatchNorm2d, torch.nn.BatchNorm3d |
| Tensorflow / Keras | tf.nn.batch_normalization, tf.keras.layers.BatchNormalization    |

<ins>Remarque :</ins> Il est tr√®s facile de trouver la documentation de la couche BN pour votre infrastructure de d√©veloppement, qu‚Äôil s‚Äôagisse de Mxnet, Matlab, Caffe ‚Ä¶  


Toutes donnent la possibilit√©s de modifier les param√®tres que cette m√©thode fait intervenir ; dans la pratique, **le param√®tre le plus important est la taille du vecteur d‚Äôentr√©e**, √† savoir :
- Le nombre de neurones de la couche cach√©e, dans le cas d‚Äôun perceptron multicouche ;
- Le nombre de filtres de la couche cach√©e, dans le cas d‚Äôun r√©seau convolutif.

<br/>

### 3. Un coup d‚Äôoeil aux r√©sultats

Si l‚Äôon est loin d‚Äôavoir compris tous les m√©canismes sous-jacents √† la couche BN (voir C.3), il y a un point sur lequel tout le monde s‚Äôaccorde : √ßa marche.

En guise de mise en bouche, regardons rapidement les r√©sultats obtenus dans l‚Äôarticle officiel [1] :


<p align="center">
  <img src="https://raw.githubusercontent.com/Johann-Huber/Johann-Huber.github.io/master/assets/gbn_1.png">
  <strong>Graphique 1 : Efficacit√© de la couche BN en entra√Ænement</strong> (source : [1]). Pr√©cision sur le jeu de validation ImageNet (2012) en fonction du nombre d‚Äôit√©ration d'entra√Ænement, pour des r√©seaux Inception avec ou sans BN, en augmentant les taux d‚Äôapprentissage pour les r√©seaux BN (1 fois, 5 fois, 30 fois le taux optimal du r√©seau Inception).
</p>

Le r√©sultat est prometteur : en ajoutant des couches BN, le **r√©seau s‚Äôentra√Æne plus vite et plus efficacement**.


Voil√† de quoi comprendre le principe des couches BN, leur int√©r√™t, et d‚Äô√™tre en mesure de les utiliser en pratique. une compr√©hension un peu plus approfondie est cependant n√©cessaire pour ne pas tomber des nues devant le comportement d‚Äôun r√©seau de neurone.


<br/>

## C) Comprendre la Normalisation par lots (BN)

### 1. Impl√©mentation

J‚Äôai r√©-impl√©ment√© cette m√©thode sous Pytorch, de mani√®re √† retrouver les r√©sultats de l‚Äôarticle officiel. Vous pourrez le trouver dans [ce repo git](https://github.com/Johann-Huber/batchnorm_pytorch/blob/main/batch_normalization_in_pytorch.ipynb).

Je vous invite √† parcourir les diverses impl√©mentations de la couche BN disponibles en ligne (presque toujours en anglais), √† commencer par celle de l'infrastructure avec laquelle vous travaillez.

<br/>

### 2. La couche BN en pratique

#### 2.1. R√©sultats de l‚Äôarticle original

J‚Äôai d√©cid√© de commencer par pr√©senter les r√©sultats obtenus avec la couche de normalisation par lots car **c‚Äôest le point sur lequel tout s‚Äôaccorde** la concernant : **Elle est efficace en pratique.**

L‚Äôarticle officiel [1] a r√©alis√© 3 exp√©riences pour √©valuer l‚Äôefficacit√© de leur m√©thode. 

La premi√®re a pour but de montrer l‚Äôefficacit√© de la normalisation par lots sur un exemple simple : Il s‚Äôagit d‚Äôentra√Æner un classificateur sur le jeu de donn√©e MNIST (reconnaissance de chiffres √©crits √† la main, issue du [c√©l√®bre article de Y. Lecun](http://yann.lecun.com/exdb/publis/pdf/lecun-90c.pdf)). Le mod√®le consiste en une succession de 3 couches enti√®rement connect√©es de 100 neurones, suivis de fonctions sigmo√Ødes. On entra√Æne le tout sur 50 000 it√©rations en utilisant un algorithme de gradient stochastique (en anglais *Stochastic Gradient Descent* - not√©e SGD), avec ou sans couche de normalisation par lots pour comparer.

Ce r√©sultat peut √™tre reproduit rapidement sans GPU, je vous invite √† essayer par vous-m√™me pour vous faire la main.


<p align="center">
  <img src="https://raw.githubusercontent.com/Johann-Huber/Johann-Huber.github.io/master/assets/gbn_2.png">
  <strong></strong> 
</p>


Bonne nouvelle, la normalisation par lots am√©liore les performances du r√©seau.

Pour la deuxi√®me exp√©rience, regardons l‚Äôimpact de cette m√©thode sur l‚Äôactivation des neurones au niveau des couches cach√©es. Voici les valeurs d‚Äôactivations obtenues sur la derni√®re couche cach√©e, juste avant le passage dans la fonction non-lin√©aire :


<p align="center">
  <img src="https://raw.githubusercontent.com/Johann-Huber/Johann-Huber.github.io/master/assets/gbn_3.png">
  <strong></strong> 
</p>

Sans la normalisation par lots, les valeurs d‚Äôactivations varient fortement au cours des premi√®res it√©rations. En revanche, les courbes d‚Äôactivations ne pr√©sentent pas d‚Äô√†-coups avec l‚Äôutilisation de couches BN. 



<p align="center">
  <img src="https://raw.githubusercontent.com/Johann-Huber/Johann-Huber.github.io/master/assets/gbn_4.png">
  <strong></strong> 
</p>


Le signal est d‚Äôailleurs moins bruit√©, lorsque l‚Äôon utilise la normalisation par lots. On constate que l‚Äôoptimiseur (en anglais *optimizer*) fait converger les poids beaucoup plus facilement.

Cet exemple simple ne montre cependant pas toute l‚Äô√©tendue de l‚Äôimpact de cette m√©thode.

L‚Äôarticle officiel explore une troisi√®me exp√©rience. Il s‚Äôagit d‚Äô√©valuer les performances de la couche BN sur un mod√®le classificateur plus complexe, appliqu√© √† la base de donn√©e ImageNet (2012). Pour cela, les auteurs adaptent un r√©seau de neurone tr√®s performant (pour l‚Äô√©poque) intitul√© [Inception](https://arxiv.org/abs/1409.4842), en lui ajoutant des couches de normalisation par lots. Ils comparent ensuite des r√©sultats du r√©seau original avec plusieurs versions modifi√©es. 

Ils obtiennent les r√©sultats suivant :


<p align="center">
  <img src="https://raw.githubusercontent.com/Johann-Huber/Johann-Huber.github.io/master/assets/gbn_1.png">
  <strong>Graphique 1 : Efficacit√© de la couche BN en entra√Ænement</strong> (source : [1]). Pr√©cision sur le jeu de validation ImageNet (2012) en fonction du nombre d‚Äôit√©ration d'entra√Ænement, pour des r√©seaux Inception avec ou sans BN, en augmentant les taux d‚Äôapprentissage pour les r√©seaux BN (1 fois, 5 fois, 30 fois le taux optimal du r√©seau Inception).
</p>


Avec :
- BN-Baseline : M√™me r√©seau qu‚ÄôInception, avec des couches de BN
- BN-x5 : M√™me r√©seau qu‚ÄôInception, avec des couches de BN, et un taux d‚Äôapprentissage (learning rate - not√© LR) multipli√© par 5
- BN-x30 : M√™me r√©seau qu‚ÄôInception, avec des couches de BN, et un taux d‚Äôapprentissage multipli√© par 30
- BN-x5-Sigmoid : M√™me r√©seau qu‚ÄôInception, avec des couches de BN, un taux d‚Äôapprentissage multipli√© par 5, et des fonction sigmo√Ødes √† la place des ReLU

Voici ce qu‚Äôon peut conclure de ces courbes :

- Ajouter des couches de BN permet de converger plus vite vers une meilleure solution (pr√©cision plus √©lev√©e) qu'en l'absence des ces couches ;

L‚Äôam√©lioration est d‚Äôailleurs bien plus nette que dans notre exemple du petit jeu de donn√©es MNIST.

- Ajouter des couches de BN permet d‚Äôutiliser au taux d‚Äôapprentissage beaucoup plus important (√† noter qu‚Äôavec un taux d‚Äôapprentissage 5 fois sup√©rieur √† celui initial, le r√©seau Inception diverge d√©j√†).

On en conclut qu‚Äôil est plus facile de trouver un taux d‚Äôapprentissage ‚Äúacceptable‚Äù, dans la mesure o√π l‚Äôintervalle de valeur entre le sous-apprentissage et l‚Äôexplosion de gradient est plus large. 

En outre, un plus grand taux d‚Äôapprentissage permet √† l‚Äôoptimiseur d‚Äô√©viter de s‚Äôarr√™ter dans un minimum local. Incit√© √† l‚Äôexploration, l‚Äôoptimiseur converge vers de meilleures solutions.

- Le mod√®le qui ne repose que sur des sigmo√Ødes atteint des r√©sultats comp√©titifs avec les mod√®les qui utilisent des ReLU.

Ce dernier point est davantage int√©ressant pour ce qu‚Äôil repr√©sente, que pour les r√©sultats obtenus avec la sigmo√Øde - qui de toutes √©vidences, sont moins bons qu‚Äôavec la ReLU. 

Pour montrer la valeur de ce r√©sultat, je me permets de paraphraser/reformuler les propos de Yann Goodfellow, r√©f√©rence dans le monde de l‚Äôapprentissage profond (inventeur des r√©seaux GANs [6], et auteur de l‚Äôouvrage de r√©f√©rence ‚ÄúDeep learning handbook‚Äù) : 

> Avant la BN, les chercheurs pensaient qu‚Äôil √©tait presqu‚Äôimpossible d‚Äôentra√Æner efficacement des mod√®les qui ne reposent que sur des sigmo√Ødes au niveau des couches cach√©es. Plusieurs approches ont √©t√© envisag√©es pour r√©soudre les probl√®mes d‚Äôinstabilit√© √† l‚Äôentra√Ænement, cherchant des m√©thodes plus optimales d‚Äôinitialisation des poids ; les embryons de solutions reposaient sur des d√©couvertes heuristiques, fragiles, et peu satisfaisantes. **L‚Äôarriv√©e de la BN a rendu exploitables des r√©seaux que l‚Äôon n‚Äôarrivaient pas √† entra√Æner efficacement** ; Cet exemple en est une preuve. 
> 
> [Yann Goodfellow](https://www.youtube.com/watch?v=Xogn6veSyxA)

Ces r√©sultats donnent un aper√ßu de l‚Äôefficacit√© remarquable de la normalisation par lots. Mais cette technique implique quelques effets qu‚Äôil est important d‚Äôavoir √† l‚Äôesprit pour l‚Äôexploiter pleinement.

	
#### 2.2. R√©gularisation, effet de bord de la normalisation par lots

La normalisation par lots repose sur les valeurs de moyenne et de variance de chaque lot (ou *batch*). Les valeurs d‚Äôactivations de chaque couche cach√©e d√©pendent donc du lot actuellement trait√© par le r√©seau. Cette transformation ajoute donc du bruit li√© aux distributions des exemples du lot au niveau de chaque couche cach√©e.

Ajouter un peu de bruit dans un r√©seau pour √©viter le sur-apprentissage ‚Ä¶ cela ressemble √† un processus de r√©gularisation, non ?

En pratique, on ne compte pas sur la normalisation par lot pour √©viter le sur-apprentissage d‚Äôun r√©seau, pour des raisons d‚Äô[orthogonalit√©s](https://en.wikipedia.org/wiki/Orthogonality_(programming)). Pour faire simple, on s‚Äôassure que chacun des modules de notre r√©seau remplisse un r√¥le pr√©cis, au lieu de compter sur plusieurs modules pour g√©rer diff√©rents probl√®mes en m√™me temps (ce qui est le meilleur moyen de ne pas aboutir √† un solution optimale).

N√©anmoins, il est int√©ressant d‚Äôavoir conscience de ce ph√©nom√®ne, puisqu‚Äôil peut expliquer un comportement impr√©vu du r√©seau (notamment lorsque l‚Äôon fait du d√©bogage).

<ins>Remarque :</ins> Plus le lot est grand, moins l‚Äôeffet de r√©gularisation sera important (minimisation de l‚Äôimpact du bruit).


#### 2.3. Param√®tres statistiques lors de la phase d‚Äô√©valuation

Le mod√®le est appel√© en phase d‚Äô√©valuation dans deux contextes :
- Dans le cadre d‚Äôun processus de validation / de test, r√©alis√©e au cours du d√©veloppement et de l‚Äôentra√Ænement du mod√®le ;
- Lors du d√©ploiement de ce dernier en conditions r√©elles (phase d‚Äôinf√©rence).

Si dans le premier cas, on peut appliquer la normalisation par lot comme en entra√Ænement dans un souci de commodit√© de calcul, l‚Äôappliquer en inf√©rence n‚Äôa vraiment pas de sens. Pourquoi ? Parce que l‚Äôon a pas n√©cessairement un lot entier √† pr√©dire. Si notre mod√®le fonctionne en temps r√©el, pour une cam√©ra embarqu√©e sur un robot par exemple, on peut n‚Äôavoir qu‚Äô√† traiter une image √† la fois. Si la taille du lot d‚Äôentra√Ænement est N, que faire des (N - 1) autres valeurs √† fournir en entr√© pour r√©aliser l‚Äôinf√©rence ? 

On peut imaginer que l‚Äôon choisit des valeurs arbitraires pour combler le lot. En fournissant le lot n¬∞1 au mod√®le, on obtient un certain r√©sultat pour l‚Äôimage qui nous int√©resse. Constituons √† pr√©sent un nouveau lot n¬∞2, √† partir d‚Äôautres valeurs arbitraires ; on obtiendrait un r√©sultat diff√©rent en sortie. Deux r√©sultats diff√©rents pour une m√™me image fournie en entr√©e du mod√®le n‚Äôest certainement pas souhaitable.

N√©anmoins, il est n√©cessaire d‚Äôavoir des valeurs ùúá et œÉ pour chacune de nos couches BN, dans la mesure o√π les param√®tres ùõΩ et ùõæ ont √©t√© entra√Æn√©es √† partir de signaux normalis√©es. 

L‚Äôastuce consiste √† d√©finir ùúápop et œÉpop, qui sont respectivement l‚Äôestimation de la moyenne et l‚Äô√©cart-type de la population √©tudi√©e. Ces param√®tres sont calcul√©s comme la moyenne sur l‚Äôensemble des (ùúálot, œÉlot) rencontr√©s lors des it√©rations.

Cependant, cette astuce peut √™tre √† l‚Äôorigine d‚Äôinstabilit√© lors de la phase d‚Äô√©valuation ; voyons cela dans la partie suivante.


#### 2.4. Stabilit√© de la couche BN

Si la normalisation par lots marche g√©n√©ralement tr√®s bien, il arrive parfois que les choses se compliquent: l'impl√©mentation de cette couche peut entra√Æner une divergence des valeurs d'activations du r√©seau durant la phase d‚Äô√©valuation.

On a mentionn√© plus haut comment sont calcul√©s ùúápop et œÉpop, de fa√ßon √† estimer les param√®tres de normalisation des valeurs d‚Äôactivation au cours de l‚Äô√©valuation : on fait la moyenne des (ùúálot, œÉlot) vus lors des pr√©c√©dentes it√©rations.

Imaginons que l‚Äôon entra√Æne un r√©seau √† partir d'images ne contenant que des chaussures de sport. Comment r√©agirait le r√©seau s'il rencontre des images contenant des chaussures de villes ?

<p align="center">
  <img src="https://raw.githubusercontent.com/Johann-Huber/Johann-Huber.github.io/master/assets/car_n_shoes2.jpg">
  Si la distribution d'entr√©e durant la phase de test est trop diff√©rente de celle de la phase d'entra√Ænement, le mod√®le peut surr√©agir √† certains signaux, entra√Ænant les couches d'activations √† diverger. 
  <br/>
  Cr√©dit : <a href="https://unsplash.com/@grailify?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText">gauche</a> et <a href="https://unsplash.com/@jimmy2018?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText">droite</a>
</p>

On devine que les valeurs d‚Äôactivation au niveau des couches cach√©es risquent de suivre des distributions tout √† fait diff√©rentes - trop, sans doute. Dans ce cas, la paire (ùúápop, œÉpop) estim√©e au cours de l‚Äôentra√Ænement n‚Äôest pas repr√©sentative de la population r√©elle que rencontre le r√©seau en phase de test. Appliquer (ùúápop, œÉpop) risque d‚Äô√©loigner le signal de la loi normale centr√©e r√©duite d√©sir√©e, pouvant mener √† une surestimation des valeurs d‚Äôactivation. 

Ce ph√©nom√®ne est amplifi√© par une propri√©t√© connue de la couche BN : au cours de l‚Äôentra√Ænement, les valeurs d'activation sont normalis√©es en tenant compte de leur propre valeur. Au moment de l‚Äôinf√©rence, on applique la normalisation √† partir des coefficients (ùúápop, œÉpop) calcul√©s pendant l‚Äôentra√Ænement : les coefficients utilis√©s pour la normalisation ne tiennent alors pas compte des valeurs d‚Äôactivations elles-m√™me.

En g√©n√©ral, on s‚Äôassure que les jeux de donn√©es d‚Äôentra√Ænement et de tests soient suffisamment proches pour que (ùúápop, œÉpop) soient coh√©rents. Dans le cas inverse, on pourrait penser que le jeu d‚Äôentra√Ænement n‚Äôest pas suffisamment large et de bonne qualit√© pour entra√Æner notre mod√®le sur la t√¢che d√©sir√©e.

Mais il existe des [cas o√π ce probl√®me survient](https://discuss.pytorch.org/t/model-eval-gives-incorrect-loss-for-model-with-batchnorm-layers/7561/38), j‚Äôen ai moi m√™me fait les frais : Au cours de la comp√©tition Kaggle de [pr√©diction de l‚Äô√©volution de la maladie de fibrose pulmonaire](https://www.kaggle.com/c/osic-pulmonary-fibrosis-progression), nous disposions d‚Äôun petit jeu de donn√©e d‚Äôentra√Ænement contenant - entres autres - des scanners 3D des poumons de chaque patient. Le contenu √©tait si riche et si divers (pour une petite centaine d‚Äôexemples), que le r√©seau convolutif avec lequel je comptais faire de l‚Äôextraction de caract√©ristiques m‚Äôa fait la f√¢cheuse surprise de retourner des valeurs astronomiques sit√¥t que l‚Äôentra√Ænement se trouvait en phase de validation...un r√©gale √† d√©boguer. ;)

Dans ce genre de contexte o√π les jeux de donn√©es d‚Äôentra√Ænement sont limit√©s, il faut faire avec les moyens du bord. 

Ajouter syst√©matiquement des BN dans notre r√©seau - en pensant que cela n‚Äôaura que des effets positifs - n‚Äôest certainement pas la meilleure strat√©gie !

#### 2.5. R√©seaux r√©currents, et normalisation par couches

En pratique, il est largement admis le principe suivant :
- Pour les r√©seaux convolutifs (CNN) : utiliser de pr√©f√©rence la Normalisation par Lots (Batch Normalization, not√©e BN)
- Pour les r√©seaux r√©currents (RNN) : utiliser de pr√©f√©rence la Normalisation par Couches (Layer Normalization, not√©e LN)

Si la BN normalise √† l‚Äô√©chelle des exemples de chaque lot, la LN normalise √† l‚Äô√©chelle des couches cach√©es. Cette deuxi√®me solution s‚Äôav√®re √™tre plus efficace avec des r√©seaux r√©currents. Une piste d‚Äôintuition r√©side dans la difficult√© √† d√©finir une strat√©gie coh√©rente avec ce type de neurones, qui repose sur la multiplication d‚Äôune m√™me matrice de poids de nombreuses fois successivement. Faut-il normaliser ind√©pendamment chaque √©tape ? Ou au contraire, en faire la moyenne, puis appliquer la normalisation r√©cursivement ?


Je ne m‚Äôattarderai pas davantage sur ce point, qui n‚Äôest pas pr√©cis√©ment l‚Äôobjet de cet article.


#### 2.6. Avant ou apr√®s la fonction non-lin√©aire ?

Historiquement, la couche BN est positionn√©e juste avant la fonction non-lin√©aire. Ceci √©tant coh√©rent avec les objectifs et les hypoth√®ses des auteurs √† l‚Äô√©poque. 

Dans leur article, ils d√©clarent :

> ‚ÄúNotre voudrions √™tre certains que le r√©seau produise toujours une activation avec une distribution statistique d√©sir√©e.‚Äù
> 
> Sergey Ioffe & Christian Szegedy [1]


En revanche, des exp√©rimentations ont montr√© que la couche BN positionn√©e apr√®s la fonction non-lin√©aire donne de meilleurs r√©sultats.

Cette petite exp√©rience en est [un exemple](https://github.com/ducha-aiki/caffenet-benchmark/blob/master/batchnorm.md#bn----before-or-after-relu).


Fran√ßois Chollet (cr√©ateur de Keras et ing√©nieur chez Google) a d‚Äôailleurs pr√©tendu √† ce sujet :

> ‚ÄúJe n‚Äôai pas v√©rifi√© ce qui est sugg√©r√© dans l‚Äôarticle original, mais je peux garantir avoir vu dans du code √©crit r√©cemment par Christian [Szegedy] que la ReLU est appliqu√©e avant la BN. Mais c‚Äôest parfois encore sujet √† d√©bat.‚Äù
> 
> [Fran√ßois Chollet](https://github.com/keras-team/keras/issues/1802)


M√™me si le vent semble tourner, beaucoup d‚Äôarchitectures commun√©ment utilis√©es pour de l‚Äôapprentissage par transfert (ResNet, mobilenet-v2, ...) placent toujours la couche BN avant.

Remarquez que les auteurs de l‚Äôarticle [2] - qui remet en question les intuitions d√©fendues par l‚Äôarticle original [1] pour expliquer l‚Äôefficacit√© de la couche BN (voir C.3.3) - ont plac√© la couche BN avant la fonction d‚Äôactivation. Ils n‚Äôapportent toutefois aucun √©l√©ment d‚Äôexplication sur cet aspect.

√Ä ma connaissance, cette question est donc toujours en discussion. 


<ins>Pour en savoir plus :</ins> [Conversation  int√©ressante](https://www.reddit.com/r/MachineLearning/comments/67gonq/d_batch_normalization_before_or_after_relu/dgqaksn/) (h√©las en anglais) sur reddit - m√™me si certains arguments sont fragiles - avec une grosse tendance en faveur de la BN apr√®s l‚Äôactivation.

<br/>


### 3. Pourquoi la couche BN est-elle efficace ?

#### 3.1. Premi√®re hypoth√®se - Confusion autour du d√©calage de covariable interne

En d√©pit de son importance, la normalisation par lots est un concept souvent mal compris. Cela tient plus d‚Äôune erreur longtemps propag√©e, que de la complexit√© de la notion.

Dans l‚Äôarticle officiel, les auteurs introduisent la BN comme suit : 

> ‚ÄúNous appelons D√©calage de Covariable Interne (en anglais *Internal Covariate Shift*) la modification au cours de l‚Äôentra√Ænement de la distribution statistique des noeuds internes d‚Äôun r√©seau profond. [...] Nous proposons un nouveau m√©canisme, que l‚Äôon appelle Normalisation par Lots (Batch Normalization), qui r√©sout en partie le probl√®me du d√©calage de covariable interne, et se faisant acc√©l√®re significativement l‚Äôentra√Ænement des r√©seaux de neurones profonds.‚Äù
> 
> Sergey Ioffe & Christian Szegedy [1]


Autrement dit, l‚Äôefficacit√© de la couche BN r√©side dans sa r√©solution (partielle) du probl√®me de d√©calage de covariable interne.


Ce point √† √©t√© remis en question dans des recherches post√©rieures [2].

Pour comprendre ce qui a suscit√© cette confusion, int√©ressons-nous √† ce qu‚Äôest le d√©calage de covariable, et aux effet de la normalisation par lots sur un r√©seau de neurones profond.


<ins>Notation :</ins> L‚Äôabr√©viation ICS fait r√©f√©rence au D√©calage de Covariable Interne (venant de l‚Äôanglais Internal Covariate Shift). 


#### Qu‚Äôest-ce que le d√©calage de covariable (au sens de la distribution) ?

Les auteurs l‚Äôont dit : le d√©calage de covariable, au sens de la distribution, d√©crit la modification de distribution statistique au cours de l‚Äôentra√Ænement d‚Äôun mod√®le, et, par extension, le d√©calage de covariable interne d√©crit ce ph√©nom√®ne √† l‚Äôint√©rieur d‚Äôun r√©seau de neurone profond.

Voyons en quoi cela pourrait poser probl√®me avec un exemple.

Supposons que l‚Äôon cherche √† entra√Æner un r√©seau classificateur qui puisse r√©pondre √† la question suivante : Cette image contient-elle une voiture ? Si l‚Äôon voulait extraire toutes les images de voiture d‚Äôune immense base de donn√©e non-√©tiquet√©e, un tel r√©seau serait tr√®s efficace. 

On aurait bien-s√ªr une image RGB en entr√©e, un ensemble de couches de neurones convolutifs, suivis de quelques couches enti√®rement connect√©es (perceptrons). On souhaite obtenir en sortie une seule valeur flottante comprise entre 0 et 1, d√©crivant la probabilit√© que l‚Äôimage contienne effectivement une voiture.

<p align="center">
  <img src="https://raw.githubusercontent.com/Johann-Huber/Johann-Huber.github.io/master/assets/sbn_5fr.jpg">
  <strong>Sch√©ma 5 : R√©seau convolutif simple pour r√©aliser une t√¢che de classification. </strong>
</p>


Pour entra√Æner un tel mod√®le, il nous faudrait un nombre cons√©quent d‚Äôimages √©tiquet√©es (1 : ‚ÄúCette image contient une voiture.‚Äù, ou 0 : ‚ÄúCette image ne contient pas de voiture).

Mais imaginons que nous ne disposions que de voiture ‚Äúclassiques‚Äù (de ville, ou de sport) pour l'entra√Ænement. Comment le mod√®le r√©agirait si nous lui demandions de classifier une image contenant une formule 1 ?

<p align="center">
  <img src="https://raw.githubusercontent.com/Johann-Huber/Johann-Huber.github.io/master/assets/car_n_shoes.jpg">
  Comme √©voqu√© dans la section (section C.2.4), le d√©calage de distribution peut d√©t√©riorer les performances du r√©seau, voir provoquer une explosion des valeurs d'activation.
  <br/>
  Cr√©dit : <a href="https://unsplash.com/@dhivakrishna?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText">gauche</a> et <a href="https://unsplash.com/@ferhat?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText">droite</a>
</p>


Dans cet exemple, il y a un d√©calage entre la distribution statistique associ√©es aux images de voitures utilis√©es pour l‚Äôentra√Ænement, et la distribution statistique associ√©es aux images de voitures de test. Plus g√©n√©ralement, il suffit d‚Äôune autre orientation, forme, luminosit√© ou condition climatique que celles vues pendant la phase d‚Äôentra√Ænement pour que nos performances se g√¢tent. On dit alors que notre mod√®le ne g√©n√©ralise pas efficacement.


Si on repr√©sentait les caract√©ristiques extraites par notre mod√®le dans l‚Äôespace de caract√©ristique, on aurait sans doute quelque chose comme √ßa :


<p align="center">
  <img src="https://raw.githubusercontent.com/Johann-Huber/Johann-Huber.github.io/master/assets/sbn_6afr.jpg">
  <strong>Sch√©ma 6.a : Pourquoi faut-il normaliser les valeur d‚Äôentr√©e d‚Äôun mod√®le ? cas non-normalis√©.</strong> √Ä l‚Äôentra√Ænement, les valeurs d‚Äôentr√©e sont tr√®s √©parses : la fonction approxim√©e sera pr√©cise l√† o√π la densit√© de points est forte. Au contraire, elle sera impr√©cise l√† o√π la densit√© est faible (pouvant prendre l‚Äôune des courbes trac√©es √† titre d‚Äôexemple).
</p>


Supposons que le symbole 'X' corresponde aux caract√©ristiques associ√©es √† une image ne contenant pas une voiture, et que le symbole 'O' corresponde aux caract√©ristiques associ√©es √† une image contenant une voiture. On peut voir qu‚Äôune m√™me fonction s√©parerait efficacement les deux ensembles. Mais il y a fort √† parier que notre mod√®le d√©duise du jeu d‚Äôentra√Ænement une fonction moins pr√©cise pour la partie sup√©rieure du graphique, puisqu‚Äôil n‚Äôy a pas de valeur d‚Äôentra√Ænement qui se situe dans cette zone pour servir de rep√®re √† l‚Äôoptimiseur. Ce dernier approximera la fonction du mieux qu‚Äôil pourra, poussant le classificateur √† faire beaucoup d‚Äôerreurs. 

Entra√Æner efficacement notre r√©seau n√©cessiterait beaucoup d‚Äôimages de voitures, de sorte que notre jeu d‚Äôentra√Ænement contiennent √† peu pr√™t toutes les variations de positions et de contexte imaginables. M√™me si dans les faits, c‚Äôest de cette fa√ßon que l‚Äôon entra√Æne de bons r√©seaux de neurones aujourd‚Äôhui, on aimerait bien que nos mod√®les puisse g√©n√©raliser √† partir du plus petit nombre d‚Äôexemple possible.

Le probl√®me pourrait √™tre r√©sum√© ainsi :

> Du point de vu du mod√®le, les images sont trop diff√©rentes les unes des autres. Autrement dit, leurs param√®tres statistiques sont trop diff√©rents. 
> 
> On dit qu‚Äôil y a **d√©calage de covariable** [au sens de la distribution] (en anglais **covariate shift**). 


On retrouve ce m√™me probl√®me dans des cas plus simples que celui des r√©seaux de neurones profonds, comme lors de r√©gressions lin√©aires. Il est apparu beaucoup plus facile de r√©soudre des probl√®mes de r√©gression lorsque le jeu d‚Äôentra√Ænement suit une loi normale centr√©e r√©duite (moyenne = 0, √©cart-type = 1) ; c‚Äôest pourquoi il est tr√®s fr√©quent de normaliser les valeurs d‚Äôentr√©es d‚Äôun mod√®le.


<p align="center">
  <img src="https://raw.githubusercontent.com/Johann-Huber/Johann-Huber.github.io/master/assets/sbn_6bfr.jpg">
  <strong>Sch√©ma 6.b : Pourquoi faut-il normaliser les valeur d‚Äôentr√©e d‚Äôun mod√®le ? cas normalis√©.</strong> Le signal d‚Äôentr√© normalis√© rend les valeurs moins √©parses √† l‚Äôentra√Ænement : il sera plus facile de trouver une fonction g√©n√©ralisante. 
</p>

Cette solution √©tait d√©j√† connue et mise en pratique avant la publication de l‚Äôarticle qui nous int√©resse ici. La couche de BN, elle, consid√®re ce probl√®me au niveau des couches cach√©es.


#### Le d√©calage de covariable interne, hypoth√®se d√©fendue par l‚Äôarticle original


<p align="center">
  <img src="https://raw.githubusercontent.com/Johann-Huber/Johann-Huber.github.io/master/assets/sbn_7fr.jpg">
  <strong>Sch√©ma 7 : Principe du d√©calage de covariable (ICS)</strong> au sens de la distribution (ICSdistrib).
</p>

Dans notre exemple du classificateur de voiture, on peut envisager les couches cach√©es comme des unit√©s qui s‚Äôactivent lorsqu‚Äôelle identifient certaines caract√©ristiques ‚Äúconceptuelles‚Äù associ√©es √† la voiture : par exemple une roue, un pneu, ou une porti√®re. On peut supposer que le m√™me ph√©nom√®ne pr√©c√©demment d√©crit a lieu au niveau des couches cach√©es. Un pneu orient√© d‚Äôune certaine fa√ßon activera un neurone selon une certaine distribution. On souhaite alors qu‚Äôun autre pneu, m√™me orient√© diff√©remment, puisse activer le m√™me neurone avec une distribution statistique comparable, afin que le r√©seau puisse en tirer des conclusions sur la probabilit√© que l‚Äôimage de d√©part contienne une voiture.

Si le signal d‚Äôentr√© pr√©sente un grand d√©calage de covariable (c‚Äôest √† dire si sa distribution statistique varie beaucoup d‚Äôun passage √† l‚Äôautre), l‚Äôoptimiseur aura plus de difficult√© √† g√©n√©raliser - autrement dit √† apprendre - √† partir de caract√©ristiques communes. √Ä l‚Äôinverse, en suivant une distribution proche de la loi normale centr√©e r√©duite, l‚Äôoptimiseur pourra plus facilement approximer une fonction g√©n√©ralisante. Les auteurs appliquent donc la m√™me strat√©gie √† l‚Äô√©chelle des couches cach√©es pour aider le r√©seau √† g√©n√©raliser √† des niveaux de caract√©ristiques plus ‚Äúconceptuels‚Äù.


N√©anmoins, il n‚Äôest pas souhaitable que tous nos signaux d‚Äôactivations suivent une loi normale centr√©e r√©duite. Cela limiterait sa capacit√© de repr√©sentativit√©, et pour cause :


<p align="center">
  <img src="https://raw.githubusercontent.com/Johann-Huber/Johann-Huber.github.io/master/assets/sbn_8.jpg">
  <strong>Sch√©ma 8 : Pourquoi il n‚Äôest pas souhaitable de contraindre l‚Äôactivation √† une loi normale centr√©e r√©duite.</strong> La sigmo√Øde ne fonctionne ici qu‚Äôen r√©gime lin√©aire.
</p>


Si l‚Äôon prend l‚Äôexemple donn√© de l‚Äôarticle original, la sigmo√Øde, un signal d‚Äôentr√© compris en 0 et 1 limiterait la fonction non-lin√©aire √† son r√©gime ‚Ä¶ lin√©aire. 

Pour pallier √† ce probl√®me, les auteurs ont alors ajout√© deux param√®tres, ùõΩ et ùõæ, pour permettre √† l‚Äôoptimiseur de d√©finir lui m√™me la moyenne (via ùõΩ) et l‚Äô√©cart type (via ùõæ) optimaux pour une t√¢che donn√©.

**‚ö† Nous arrivons au point qui est souvent l‚Äôobjet de confusion.** Pendant quelques ann√©es apr√®s la sortie de l‚Äôarticle original, on a d√©duit de l‚Äôefficacit√© de la couche BN l‚Äôexplication suivante :


**Hypoth√®se 1 :**

> BN -> normalisation du signal √† chaque couche cach√©e -> ajout de deux param√®tres √† ajuster pour profiter de tous les r√©gimes d‚Äôactivations -> facilite l‚Äôentra√Ænement

Ce qui situe d‚Äôint√©r√™t de la BN dans le fait que cette couche assure une distribution proche d‚Äôun loi normale centr√©e r√©duite, facilitant la g√©n√©ralisation. Ceci a √©t√© remis en question, pr√©f√©rant une autre explication que l‚Äôon pourrait √©noncer comme suit :


**Hypoth√®se 2 :**

> BN -> normalisation du signal √† chaque couche cach√©e -> diminue l‚Äôinterd√©pendance des couches cach√©es entre elles sur les param√®tres statistiques -> facilite l‚Äôentra√Ænement

Ce n‚Äôest plus tout √† fait la m√™me chose. Ici, le passage √† la loi normale centr√©e r√©duite n‚Äôest plus qu‚Äôun moyen de r√©duire l'interd√©pendance des couches les unes avec les autres. √âtudions cette nouvelle hypoth√®se.



#### 3.2. Deuxi√®me hypoth√®se : limiter l‚Äôinterd√©pendance de distributions 

*Note de r√©daction : Ne disposant pas de preuves irr√©futables, je me permets de m‚Äôappuyer tr√®s largement sur les explications de [Yann Goodfellow √† ce sujet](https://www.youtube.com/watch?v=Xogn6veSyxA), et sur quelques discussions en ligne cit√©es en r√©f√©rences.*

Consid√©rons l‚Äôexemple suivant :

<p align="center">
  <img src="https://raw.githubusercontent.com/Johann-Huber/Johann-Huber.github.io/master/assets/sbn_9fr.jpg">
  <strong>Sch√©ma 9 : Principe simplifi√© d‚Äôun r√©seau de neurone profond,</strong> compos√© uniquement de transformation lin√©aires.
</p>



O√π (a), (b), (c), (d) et (e) sont les couches successives d‚Äôun r√©seau de neurones. Notre cas est tr√®s simple, il s‚Äôagit d‚Äôun r√©seau constitu√© d‚Äôune succession de transformations lin√©aires. On cherche √† entra√Æner ce r√©seau avec la m√©thode de descente de gradient (*Stochastic Gradient Descent*, SGD).

Pour calculer la mise √† jour des poids de (a), on calcule le gradient en partant de la fin. On obtient :
<p align="center">
  grad(a) = b * c * d * e
</p>

On se place d‚Äôabord dans le cas d‚Äôun r√©seau sans couche BN. On conclut de l‚Äô√©quation √©tablie ci-dessus que si tous les gradients sont grands, grad(a) aura une valeur tr√®s √©lev√©e. √Ä l‚Äôinverse, des gradients tr√®s petits sur les couches suivantes forceront grad(a) vers une valeur presque n√©gligeable. 

Si l‚Äôon s‚Äôint√©resse au distributions statistiques qui se pr√©sentent √† l‚Äôentr√©e de chacune de ces couches, on s‚Äôaper√ßoit de l‚Äôinterd√©pendance entre les couches du r√©seau : Une modification des poids de (a) modifiera la distribution du signal entrant dans (b), qui aura √† terme des cons√©quences sur celles des signaux entrant dans (d) et (e). Ceci est probl√©matique pour la stabilisation de l‚Äôentra√Ænement : pour ajuster la distribution statistique d‚Äôune couche, il faut tenir compte de l‚Äôensemble de la cha√Æne. 

Or, la SGD est une m√©thode qui s‚Äôint√©resse aux relations du 1er ordre (d√©riv√©e premi√®re appliqu√©e √† une couche par rapport √† la pr√©c√©dente). Elle ne tient donc pas compte des interactions mentionn√©es pr√©c√©demment !


<p align="center">
  <img src="https://raw.githubusercontent.com/Johann-Huber/Johann-Huber.github.io/master/assets/sbn_10fr.jpg">
  <strong>Sch√©ma 10 : Principe de l‚Äôhypoth√®se n¬∞2.</strong> En normalisant puis ajustant le signal avec ùõΩ et ùõæ, la couche BN simplifie le contr√¥le du signal au niveau de chaque couche cach√©e.
</p>



Ajouter la couche BN att√©nue tr√®s largement l‚Äôinterd√©pendance entre les couches pendant l‚Äôapprentissage. La normalisation agit comme une porte que l‚Äôoptimiseur peut ajuster √† partir des seuls param√®tres ùõΩ et ùõæ. Il n‚Äôest alors plus n√©cessaire de tenir compte de tous les param√®tres du r√©seau pour avoir des informations statistiques sur une couche cach√©e.

<ins>Remarque :</ins> L‚Äôoptimiseur peut alors se permettre de faire de bien plus grosses modifications de poids sur chacune des couches, sans que cela n‚Äôalt√®re le travail r√©alis√© sur les couches successives. Il est donc beaucoup plus facile de d√©terminer des hyperparam√®tres qui convergeront vers une solution optimale.

> Cet exemple met de c√¥t√© l‚Äôhypoth√®se dans laquelle la BN servirait √† faire tendre les valeurs d‚Äôactivations des couches cach√©es vers une loi normale centr√©e r√©duite. 
> 
> Ici, il s‚Äôagit de **faciliter le travail de l‚Äôoptimiseur** en lui permettant d‚Äô**ajuster les distributions statistiques internes** en jouant sur seulement **deux param√®tres √† la fois**.

Il s‚Äôagit n√©anmoins d‚Äôintuitions autour du fonctionnement de la normalisation par lot, et il n‚Äôexiste pas, √† ma connaissance, de solides preuves de ces hypoth√®ses. 

Un article paru en 2019 par une √©quipe du MIT a apport√© une contribution int√©ressante √† la compr√©hension de l‚Äôefficacit√© de la couche BN. Les auteurs remettent tr√®s fortement en question le lien entre l‚Äôefficacit√© de la couche BN et la r√©duction du d√©calage de covariable interne, au sens de la distribution (premi√®re hypoth√®se) !


#### 3.3. Troisi√®me hypoth√®se - lissage du paysage d‚Äôoptimisation

*Note de r√©daction : Dans cette partie, je m‚Äôefforce de synth√©tiser l‚Äôarticle [2], pour pr√©senter leurs principales conclusions quant aux propri√©t√©s de la couche BN. Cet article est dense, je vous invite √† vous y pencher avec plus d‚Äôattention si ces concepts vous int√©ressent.*

Int√©ressons-nous directement √† la deuxi√®me exp√©rience de cet article. Les auteurs entra√Ænent trois [r√©seaux VGG](https://arxiv.org/abs/1409.1556) (sur CIFAR-10) :
Le premier sans couche BN ;
Le deuxi√®me avec des couches BN ;
Le troisi√®me est identique au deuxi√®me, √† ceci pr√™t qu‚Äôils ajoutent explicitement de l‚ÄôICS au niveau des couches cach√©es en ajoutant du bruit (valeurs al√©atoires ajout√©es/multipli√©es √† la moyenne/variance) ; 

Ils observent ensuite la pr√©cision obtenue par chaque mod√®le, ainsi que l‚Äô√©volution des distributions d‚Äôactivations au niveau des couches cach√©es. Voici les r√©sultats obtenus :


<p align="center">
  <img src="https://raw.githubusercontent.com/Johann-Huber/Johann-Huber.github.io/master/assets/gbn_6.png">
  <strong>Graphique 6 : Impact de la couche BN sur l‚ÄôICSdistrib</strong> (source : [2]). Les deux r√©seaux qui utilisent la couche BN s‚Äôentra√Ænent plus vite que le r√©seau standard ; ajouter explicitement de l‚ÄôICSdistrib sur un r√©seau normalis√© ne d√©t√©riore pas ces propri√©t√©s.
</p>


On observe que le 3e r√©seau a, comme pr√©vu, un tr√®s fort ICS. Pourtant, cela ne l‚Äôemp√™che pas d‚Äô√™tre entra√Æn√© de mani√®re plus rapide et plus stable que le r√©seau standard. Les performances sont assez similaires au r√©seau avec des couches BN mais sans ajout explicit d‚ÄôICS, sugg√©rant que l‚Äôefficacit√© de la BN n‚Äôest pas li√© √† la diminution de l‚ÄôICS, comme le soutient l‚Äôhypoth√®se 1.

N‚Äô√©cartons pas l‚ÄôICS trop vite : la d√©finition du d√©calage de covariable interne (donn√©e dans l‚Äôarticle original de la couche BN) li√©e √† la distribution est peut-√™tre insatisfaisante. Les auteurs de [2] ont explor√©s une autre d√©finition de l‚ÄôICS, cette fois-ci exprimant les propri√©t√© d‚Äôoptimisation du mod√®le. En voici une d√©finition :

> Consid√©rons une entr√©e fixe √† notre mod√®le, not√©e X. 
> 
> On d√©finit le **d√©calage de covariable interne** d‚Äôun point de vu de **l‚Äôoptimisation** (not√© ICSopti ), la diff√©rence entre le **gradient** calcul√© au niveau d‚Äôune couche k apr√®s avoir r√©tropropag√© l‚Äôerreur **L(X)It**, et le gradient calcul√© au niveau de la m√™me couche k apr√®s la mise √† jour des poids des couches pr√©c√©dentes **L(X)It+1**.


Cette d√©finition a pour but de focaliser l‚Äôattention sur le gradient de l‚Äôerreur, plus que sur la distribution des valeurs d‚Äôactivation. On cherche ainsi √† s‚Äôint√©resser directement au probl√®me d‚Äôoptimisation sous-jacent pour comprendre l‚Äôefficacit√© de la couche BN, et voir le lien que peut avoir l‚ÄôICS sur l‚Äôentra√Ænement.

L‚Äôexp√©rience suivante √©value cette nouvelle approche de l‚ÄôICS. Pour cela, les auteurs √©valuent l‚Äôimpact de la normalisation par lots sur l‚ÄôICSopti en regardant son √©volution au cours de l‚Äôentra√Ænement d‚Äôun r√©seau avec / sans couche BN. Pour quantifier la diff√©rence entre les gradients √©voqu√©es dans la d√©finition de l‚ÄôICSopti , les auteurs calculent :
- La diff√©rence L2 : Les gradients ont-ils une norme proche avant et apr√®s la mise √† jour des poids ? Id√©alement : L2-diff = 0 ;
- Le cosinus de l‚Äôangle orient√© : Les gradients ont-ils une direction similaire avant et apr√®s la mise √† jour des poids ? Id√©alement: cos(grad(k)It , grad(k)It+1) = 1 .


<p align="center">
  <img src="https://raw.githubusercontent.com/Johann-Huber/Johann-Huber.github.io/master/assets/gbn_7.png">
  <strong>Graphique 7 : Impact de la couche BN sur l‚ÄôICSopti</strong> (source : [2]). Les diff√©rence de normes et d‚Äôangles de gradient sugg√®re qu‚Äôelle n‚Äôemp√™che pas le d√©calage ; le ph√©nom√®ne semble au contraire s‚Äôaggraver.
</p>

Les r√©sultats sont surprenants : Le r√©seau qui repose sur des couches de normalisation par lots a un d√©calage de covariable interne similaire, voir sup√©rieur, au r√©seau standard. Rappelons-le, le r√©seau qui utilise des couche de BN (courbe bleue) s‚Äôentra√Æne beaucoup plus vite et converge vers une meilleure solution que celui qui n'utilise pas ces couches (courbe rouge) !

D√©cid√©ment, l‚ÄôICS - dans les d√©finitions qu‚Äôon en a donn√© - n‚Äôa pas l‚Äôair li√© aux performances d‚Äôentra√Ænement.

La normalisation par lots aurait donc d‚Äôautres effets sur l‚Äôentra√Ænement, qui aboutissent √† une convergence plus rapide vers une meilleure solution.

Int√©ressons nous directement au probl√®me de l‚Äôoptimisation : quel est l‚Äôimpact de la couche BN sur le paysage d‚Äôoptimisation (en anglais : *optimization landscape*) ?

Voici la derni√®re exp√©rience que nous allons aborder dans cet article :

<p align="center">
  <img src="https://raw.githubusercontent.com/Johann-Huber/Johann-Huber.github.io/master/assets/sbn_11.jpg">
  <strong>Sch√©ma 11 : Exploration du paysage d‚Äôoptimisation</strong> dans la direction du gradient. Exp√©rience men√©e dans l‚Äôarticle [2].
</p>

√Ä partir d‚Äôun m√™me gradient, on r√©alise la mise √† jour des poids pour diff√©rents pas d‚Äôoptimisation (comparable √† une augmentation du taux d‚Äôapprentissage !). Intuitivement, on d√©finit une direction √† partir d‚Äôun certain point de l‚Äôhyperplan dans l‚Äôespace des param√®tres, puis on explore le paysage d‚Äôoptimisation en suivant cette direction de plus en plus loin. 

√Ä chaque pas, on rel√®ve le gradient et la perte. On peut donc comparer les diff√©rents point du paysage d‚Äôoptimisation avec le point de d√©part. Si l‚Äôon rel√®ve de fortes variations, le paysage est tr√®s instable et le gradient est incertain : de grands pas risquerait de d√©t√©riorer notre optimisation. Au contraire, si les variations relev√©es sont petites, le paysage est stable et le gradient est plus s√ªr : on peut alors se permettre de plus grands pas sans compromettre l‚Äôoptimisation ! Autrement dit, on peut appliquer un plus grand taux d‚Äôapprentissage, et atteindre une convergence plus rapide. Ceci √©tant des propri√©t√©s bien connus des utilisateurs de la couche BN‚Ä¶

Place aux r√©sultats :

<p align="center">
  <img src="https://raw.githubusercontent.com/Johann-Huber/Johann-Huber.github.io/master/assets/gbn_8.png">
  <strong>Graphique 8 : Impact de la couche BN sur le lissage du paysage d‚Äôoptimisation</strong> (source : [2]). Avec la normalisation par lots, on constate l‚Äôatt√©nuation des fortes variations du gradient.
</p>

On peut voir tr√®s distinctement que le paysage d‚Äôoptimisation est bien plus lisse avec la couche BN que sans. 

Nous tenons enfin une piste d‚Äôexplication : Par un moyen ou un autre, la couche de normalisation lisse le paysage d‚Äôoptimisation. Le travail de l‚Äôoptimiseur en est grandement facilit√© : on peut d√©finir un taux d‚Äôapprentissage plus important, √©tant moins soumis au risque de disparition de gradient (poids bloqu√©s sur une hypersurface plate) ou √† l‚Äôexplosion de gradient (poids entra√Æn√© par un minimum local abrupt).

Nous sommes √† pr√©sent en mesure de formuler la troisi√®me hypoth√®se, d√©fendue par cet article [2] :


**Hypoth√®se 3 :**

> BN -> normalisation du signal √† chaque couche cach√©e -> lissage du paysage d‚Äôoptimisation -> entra√Ænement plus stable et plus rapide.


Une nouvelle interrogation s‚Äôimpose : par quel moyen la normalisation par lots lisse-t-elle le paysage d‚Äôoptimisation ?

Pour finir, les auteurs ont constat√© que cet effet n‚Äôest pas unique √† la normalisation par lots, obtenant des performances d‚Äôentra√Ænement comparables avec d‚Äôautres formes de normalisation (par exemple la normalisation L1 ou L2). Les bonnes performances de la normalisation par lots seraient donc fortuites, mettant en oeuvre un m√©canisme dont nous n‚Äôavons pas encore saisi tous les ressorts. Par ailleurs, leur article explore d‚Äôun point de vu th√©orique les cons√©quences de la normalisation par lots sur les propri√©t√©s de continuit√©s de la fonction de co√ªt. Ils montrent que la normalisation rend la fonction Lipschitzienne.

En d√©finitive, cet article bat en br√®che l‚Äôid√©e commun√©ment admise que l‚Äôefficacit√© de la couche BN reposerait sur l‚Äôatt√©nuation du d√©calage de covariable interne (au sens de la distribution comme au sens de l‚Äôoptimisation). En revanche, il souligne l‚Äôeffet de lissage du paysage d‚Äôoptimisation que la normalisation implique. 

Si cet article √©nonce une hypoth√®se quant √† la raison pour laquelle l‚Äôentra√Ænement est plus rapide, il n‚Äôapporte pas d‚Äô√©l√©ment √† propos des propri√©t√©s g√©n√©ralisantes de la couche BN. 

Une hypoth√®se √† ce sujet est bri√®vement √©voqu√© en fin d‚Äôarticle, soutenant que le lissage du paysage d‚Äôoptimisation permettrait au mod√®le de converger vers des minimums plats, ayant de meilleures propri√©t√©s g√©n√©ralisantes.

Soulignons cependant que leur principal contribution est la remise en question de la vision commun√©ment admise depuis la sortie de l‚Äôarticle officiel - ce qui est, d√©j√†, significatif.

<br/>
#### 4. Bilan : Pourquoi la BN est efficace ? Ce que l‚Äôon sait aujourd‚Äôhui


- La couche BN **att√©nue le d√©calage de covariable interne** (ICS)
	- ‚ùå **Faux** : [2] a montr√© qu‚Äôen pratique, on ne distingue pas de corr√©lation entre cet effet et les performances d‚Äôentra√Ænement.

- La couche BN **facilite la t√¢che de l‚Äôoptimiseur** en lui permettant d‚Äô**ajuster la distribution des couches cach√©es** √† partir de **2 param√®tres seulement**
	- ‚ùì **Peut-√™tre** : Cette hypoth√®se met l‚Äôaccent sur l‚Äôinterd√©pendance des param√®tres du r√©seau entre eux, rendant difficile l‚Äôoptimisation des poids vers une solution optimale. Pas de preuve solide n√©anmoins.
- La couche BN **reparam√©trise le probl√®me d‚Äôoptimisation intrins√®que, le rendant plus stable et plus lisse**
	- ‚ùì **Encore tr√®s incertain** : Leurs r√©sultats n‚Äôont pas encore √©t√© bouscul√©s. Les preuves semblent encore fragiles (reposant principalement sur quelques exp√©riences, et sur quelques √©l√©ments de d√©monstrations th√©oriques).

De nombreuses questions demeurent, donc, et la couche BN est toujours l‚Äôobjet de recherches √† l‚Äôheure o√π j‚Äô√©cris ces lignes. Mais l'√©valuation de ces hypoth√®ses nous donnent une meilleure compr√©hension de la couche de normalisation par lots, nous √©loignant des justifications erron√©es que l‚Äôon a eu longtemps √† l‚Äôesprit. 

Ces questions ouvertes ne nous emp√™che cependant pas de profiter de l‚Äôefficacit√© des couches BN dans un r√©seau !

<br/>
### En r√©sum√©

**La normalization par lots** (ou *Batch-normalization* - not√©e BN) constitue **une des plus grandes avanc√©es** li√©es √† l‚Äô√©mergence de **l‚Äôapprentissage profond**. 

Reposant sur la succession de deux transformations lin√©aires, cette m√©thode rend les **entra√Ænements** de r√©seaux de neurones profonds (perceptrons multicouches ou r√©seaux convolutifs) **plus rapides** et **plus stables**. L‚Äôint√©r√™t majeur de cette technique r√©side dans le fait qu‚Äôelle **att√©nue tr√®s largement** l‚Äôimpact de **l‚Äôinterd√©pendance** entre les poids du r√©seau sur les param√®tres statistiques au niveau des couches cach√©es. 

√Ä l‚Äôheure o√π j‚Äô√©cris cet article, beaucoup des mod√®les parmi les plus utilis√©es en r√©seaux de neurones profond exploitent massivement cette m√©thode (ex: ResNet[4], EfficientNet [5], ...).

<br/>
### Questions ouvertes

M√™me si la normalisation par lots a montr√© son efficacit√© en pratique depuis des ann√©es, ce concept est encore mal compris. Et si certains articles ont bouscul√© la compr√©hension largement admise pendant des ann√©es par la communaut√© scientifique, les m√©canismes intrins√®ques qui r√©gissent ce concept restent tr√®s incertains.

Voici une liste non-exhaustive des questions ouvertes √† propos de la couche BN :
- Comment la normalisation par lots aide le r√©seau √† g√©n√©raliser plus efficacement ?
- La couche BN est-elle la meilleure solution de normalisation pour faciliter l‚Äôoptimisation ?
- Dans quelle mesure les param√®tres ùõΩ et ùõæ influencent le lissage du paysage d‚Äôoptimisation ?
- Les exp√©rimentations montrant l‚Äôeffet de lissage de la couche BN sur le paysage d‚Äôoptimisation ont √©t√© r√©alis√©es dans des conditions de court-terme ; on a regard√© l‚Äô√©volution du gradient et de la fonction de co√ªt √† partir d‚Äôune seule it√©ration, testant diff√©rentes longueurs de pas. Au del√† de l‚Äôimpact direct que ces exp√©riences mettent en lumi√®re, qu‚Äôen est-il sur le long terme ? L‚Äôinterd√©pendances des poids provoque-t-elle d‚Äôautres effets remarquables sur le paysage d‚Äôoptimisation ?

<br/>
#### Remerciements

Merci √† [Lou Hacquet-Delepine](https://www.instagram.com/louhacquetdelepine/) pour la r√©alisation des sch√©mas, et pour son aide pr√©cieuse de relecture !

<br/>
#### R√©f√©rences

[1] [Ioffe, S., & Szegedy, C. (2015, June). Batch normalization: Accelerating deep network training by reducing internal covariate shift. In International conference on machine learning (pp. 448-456). PMLR.](https://arxiv.org/abs/1502.03167) 

[2] [Santurkar, S., Tsipras, D., Ilyas, A., & Madry, A. (2018). How does batch normalization help optimization?. arXiv preprint arXiv:1805.11604.](https://arxiv.org/pdf/1805.11604.pdf)

[3] [Szegedy, C., Liu, W., Jia, Y., Sermanet, P., Reed, S., Anguelov, D., ‚Ä¶ & Rabinovich, A. (2015). Going deeper with convolutions, Proceedings of the IEEE conference on computer vision and pattern recognition](https://arxiv.org/abs/1409.4842) 

[4] [He, K., Zhang, X., Ren, S., & Sun, J. (2016). Deep residual learning for image recognition. In Proceedings of the IEEE conference on computer vision and pattern recognition](https://arxiv.org/abs/1512.03385)

[5] [Tan, M., & Le, Q. V. (2019). Efficientnet: Rethinking model scaling for convolutional neural networks, arXiv preprint arXiv:1905.11946.](https://arxiv.org/abs/1905.11946)

[6] [Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., Courville, A. Bengio, Y. (2014), Generative adversarial nets, Advances in neural information processing systems](https://proceedings.neurips.cc/paper/2014/hash/5ca3e9b122f61f8f06494c97b1afccf3-Abstract.html)

<br/>
#### Pour aller plus loin

Brillante [pr√©sentation de Ian Goodfellow](https://www.youtube.com/watch?v=Xogn6veSyxA) (malgr√© la qualit√© sonore), dont le d√©but traite de la normalisation par lot.

[Pr√©sentation de l‚Äôarticle ‚ÄúComment la normalisation par lots aide l‚Äôoptimisation ?‚Äù](https://www.microsoft.com/en-us/research/video/how-does-batch-normalization-help-optimization/) par l‚Äôun des auteurs, lors d'une intervention chez Microsoft ; l‚Äôaudience est incisive sur les questions, et les d√©bats d√©clench√©s sont passionnants.


Positionnement de la [BN avant ou apr√®s l‚Äôactivation sur stackoverflow](https://stackoverflow.com/questions/39691902/ordering-of-batch-normalization-and-dropout)

Positionnement de la [BN avant ou apr√®s l‚Äôactivation sur reddit](https://www.reddit.com/r/MachineLearning/comments/67gonq/d_batch_normalization_before_or_after_relu/dgqaksn/)


